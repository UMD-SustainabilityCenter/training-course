{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011292b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "auto-generated-toc"
    ]
   },
   "source": [
    "## Table of Contents\n",
    "- [Linear Regression](#Linear-Regression)\n- [Implementation](#Implementation)\n  - [Uploading the data](#Uploading-the-data)\n  - [Data Preprocessing](#Data-Preprocessing)\n  - [Model Implementation](#Model-Implementation)\n- [üè† Home](../../../../welcomePage.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddf608-ef2d-46de-8272-044ad8b8293b",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "**Linear Regression** is a statistical method used to model the relationship between a dependent variable and one or more independent variables. The dependent variable represents the target feature that is to be predicted, and the independent variables are the features used to predict the target. The goal is to find a linear equation that best predicts the dependent variable from the independent variables.\n",
    "\n",
    "### Formula\n",
    "\n",
    "The equation for a linear regression line is:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n + \\epsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "-  ùë¶  is the dependent variable,\n",
    "-  ùëã_1, ùëã_2, ..., ùëã_n are the independent variables,\n",
    "-  ùõΩ_0, ùõΩ_1, ùõΩ_2, ..., ùõΩ_n  are the coefficients,\n",
    "- ùúñ is the error term, which accounts for the variability in ùë¶ not explained by the independent variables.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "Linear regression assumes:\n",
    "1. **Linearity:** The relationship between the predictors and the response is linear.\n",
    "2. **No multicollinearity:** Predictors are not perfectly collinear or highly correlated.\n",
    "3. **Homoscedasticity:** The variance of residual is the same for any value of the predictors.\n",
    "4. **Independence:** Observations are independent of each other.\n",
    "5. **Normality:** For any fixed value of $X$, $y$ is normally distributed.\n",
    "\n",
    "### Types\n",
    "\n",
    "There are two main types of linear regression:\n",
    "- **Simple Linear Regression:** Only one independent variable is used to predict the dependent variable. It models the relationship between the dependent variable and one independent variable using a linear equation.\n",
    "- **Multiple Linear Regression:** More than one independent variable is used to predict the dependent variable.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Linear regression is widely used in various fields including economics, biology, engineering, and social sciences to:\n",
    "- Predict outcomes,\n",
    "- Determine strength of predictors,\n",
    "- Forecast future trends,\n",
    "- Model relationships.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here's a simple example of a linear regression model predicting 3D printing material cost based on their print strength. The equation might look like:\n",
    "\n",
    "$$\n",
    "\\text{Material Cost} = \\beta_0 + \\beta_1 \\times \\text{Print Strength}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50cfc91-ee85-4bf1-a4d5-c9ea18ade8a1",
   "metadata": {},
   "source": [
    "<img src=\"SimpleLinearRegression.png\" alt=\"alt text\" title=\"Title\" style=\"width:800px;height:250px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea04537",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e289ffd",
   "metadata": {},
   "source": [
    "## Uploading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b646f1d-f913-4db8-b092-7c5399cec683",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617348c-78c8-4dc6-980b-998e7ca58b14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# List all .csv and Excel files in the current directory\n",
    "supported_extensions = ['.csv', '.xlsx', '.xls']\n",
    "files = [f for f in os.listdir('./data/') if any(f.endswith(ext) for ext in supported_extensions)]\n",
    "\n",
    "# Create a dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=files,\n",
    "    description='Files:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a button widget\n",
    "button = widgets.Button(\n",
    "    description='Select',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to select file',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Output widget to display messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_file = dropdown.value\n",
    "        global data\n",
    "        if selected_file.endswith('.csv'):\n",
    "            data = pd.read_csv('./data/'+selected_file)\n",
    "        elif selected_file.endswith(('.xlsx', '.xls')):\n",
    "            data = pd.read_excel('./data/'+selected_file)\n",
    "        print(f\"File '{selected_file}' uploaded as data.\")\n",
    "\n",
    "# Attach the function to the button widget\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the dropdown, button widgets, and initial message within the output widget\n",
    "with output:\n",
    "    print(\"Please select a file from the dropdown and click 'Select'.\")\n",
    "display(output)\n",
    "display(dropdown)\n",
    "display(button)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8b637",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd4bee-8228-465a-a125-ba5bac723ce9",
   "metadata": {},
   "source": [
    "**Filling Null Values in Data Preprocessing:**\n",
    "Filling NaNs is crucial because many machine learning algorithms cannot handle missing data and will fail if they encounter NaNs. It ensures the dataset is complete and consistent, allowing effective model training. Handling missing values properly maintains the integrity of the dataset.\n",
    "\n",
    "**Encoding Categorical Data:**\n",
    "Many machine learning algorithms require numerical input, so categorical data must be converted into a numerical format. Encoding ensures that non-numeric attributes can be used to train the model, improving performance and accuracy. Common methods include one-hot encoding and label encoding.\n",
    "\n",
    "**Normalizing Data:**\n",
    "Normalization scales data to a specific range, typically [0, 1] or [-1, 1]. It ensures that features with different scales do not disproportionately affect the model's performance. Normalizing data helps each feature contribute equally, enhancing convergence speed and model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f836c86-7d44-479e-afd6-0586c2311e09",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to deal with null and categorical values and to normalize the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e718944",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Widgets for selecting operations and methods\n",
    "fill_method_dropdown = widgets.Dropdown(\n",
    "    options=[('None', None), ('Zero', 'zero'), ('Mean', 'mean'), ('Median', 'median')],\n",
    "    value=None,\n",
    "    description='Fill Method:',\n",
    ")\n",
    "\n",
    "remove_nulls_checkbox = widgets.Checkbox(value=False, description='Remove Nulls')\n",
    "encode_categorical_checkbox = widgets.Checkbox(value=False, description='Encode Categorical')\n",
    "normalize_data_checkbox = widgets.Checkbox(value=False, description='Normalize Data')\n",
    "\n",
    "# Button to apply selected operations\n",
    "apply_button = widgets.Button(description='Apply All', button_style='info')\n",
    "\n",
    "# Button to display data\n",
    "show_data_button = widgets.Button(description='Show Data')\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def apply_operations():\n",
    "    global data\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # Fill missing values based on selected method\n",
    "        if fill_method_dropdown.value:\n",
    "            if fill_method_dropdown.value == 'zero':\n",
    "                data = data.fillna(0)\n",
    "            elif fill_method_dropdown.value in ['mean', 'median']:\n",
    "                # Apply fill method only to numeric columns\n",
    "                numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "                for column in numeric_cols:\n",
    "                    if data[column].sum() != 0:\n",
    "                        if fill_method_dropdown.value == 'mean':\n",
    "                            mean_value = data[column].mean()\n",
    "                            data[column] = data[column].fillna(mean_value)\n",
    "                        elif fill_method_dropdown.value == 'median':\n",
    "                            median_value = data[column].median()\n",
    "                            data[column] = data[column].fillna(median_value)\n",
    "            print(f\"Missing values filled with {fill_method_dropdown.value}.\")\n",
    "\n",
    "        if remove_nulls_checkbox.value:\n",
    "            data = data.dropna()  # Remove remaining null values\n",
    "            print(\"Remaining null values removed.\")\n",
    "        if encode_categorical_checkbox.value:\n",
    "            # Apply label encoding to categorical columns\n",
    "            label_encoder = LabelEncoder()\n",
    "            categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "            for col in categorical_cols:\n",
    "                data[col] = label_encoder.fit_transform(data[col].astype(str))\n",
    "            print(\"Categorical data encoded using label encoding.\")\n",
    "        if normalize_data_checkbox.value:\n",
    "            # Normalize numeric columns using MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "            data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "            print(\"Data normalized.\")\n",
    "\n",
    "def show_data(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        display(data.head())  # Show the head of the DataFrame\n",
    "\n",
    "apply_button.on_click(lambda b: apply_operations())\n",
    "show_data_button.on_click(show_data)\n",
    "\n",
    "# Layout the widgets\n",
    "widgets.VBox([\n",
    "    widgets.Label('Select Fill Method and Operations:'),\n",
    "    fill_method_dropdown,\n",
    "    remove_nulls_checkbox,\n",
    "    encode_categorical_checkbox,\n",
    "    normalize_data_checkbox,\n",
    "    apply_button,\n",
    "    show_data_button,\n",
    "    output\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee7dd1-4288-460d-9cd4-79340fd7df24",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to visualize the heatmap and the distributions of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba8a60-d959-4aca-9c3a-21cb8030f2ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Sample DataFrame loading\n",
    "# data = pd.read_csv('your_data.csv')  # Uncomment this and replace with your DataFrame\n",
    "\n",
    "# Output widget to display the plots\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "def display_heatmap():\n",
    "    with output_widget:\n",
    "        output_widget.clear_output(wait=True)\n",
    "        # Display heatmap only for numeric columns\n",
    "        numeric_cols = data.select_dtypes(include=['int64', 'float64', 'float32'])\n",
    "        if not numeric_cols.empty:\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(numeric_cols.corr(), fmt=\".2f\", cmap='Blues')\n",
    "            plt.title('Heatmap of Numeric Features')\n",
    "            plt.xticks(rotation=45, ha='right')  # Rotate x labels for better visibility\n",
    "            plt.yticks(rotation=0)  # Ensure y labels are readable\n",
    "            plt.tight_layout()  # Adjust layout to fit all elements\n",
    "            plt.show()\n",
    "\n",
    "# Create a dropdown to select the column\n",
    "column_selector = widgets.Select(\n",
    "    options=['Heatmap'] + list(data.columns),\n",
    "    description='Select:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "\n",
    "def on_column_selected(change):\n",
    "    column = change['new']\n",
    "    if column == 'Heatmap':\n",
    "        display_heatmap()\n",
    "    else:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output(wait=True)\n",
    "            if pd.api.types.is_numeric_dtype(df[column]):\n",
    "                # Numeric column: plot distribution\n",
    "                plt.figure(figsize=(5, 3))\n",
    "                sns.histplot(df[column], kde=True, color='skyblue')\n",
    "                plt.title(f'Distribution of {column}')\n",
    "                plt.xlabel(column)\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "            else:\n",
    "                # Categorical column: plot pie chart\n",
    "                pie_data = df[column].value_counts()\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.pie(pie_data, labels=pie_data.index, autopct='%1.1f%%', startangle=140, colors=plt.cm.Pastel1.colors)\n",
    "                plt.title(f'Distribution of {column}')\n",
    "                plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "                plt.show()\n",
    "\n",
    "# Watch for changes in the dropdown\n",
    "column_selector.observe(on_column_selected, names='value')\n",
    "\n",
    "# Initial display\n",
    "display(column_selector, output_widget)\n",
    "display_heatmap()  # Display the heatmap by default when the notebook is run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36f4f0",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36c734",
   "metadata": {},
   "source": [
    "### Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca4e6e-04e9-48d8-b3e8-4b503d75de79",
   "metadata": {},
   "source": [
    "**Train and Test Splitting:**\n",
    "Train and test splitting divides a dataset into two subsets: one for training the model and one for evaluating its performance. It allows for an unbiased assessment of the model's generalization to new data. This helps detect overfitting (when the model performs well on training data but poorly on new data) and ensures good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3800a-4499-43f2-af8b-6f106778988c",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to split the data into training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199af03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Sample DataFrame loading (replace this with your actual DataFrame)\n",
    "# data = pd.read_csv('your_data.csv')  # Uncomment this and replace with your DataFrame\n",
    "\n",
    "# Slider for selecting the train-test split percentage\n",
    "split_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.1,\n",
    "    description='Train/Test Split:',\n",
    "    readout_format='.1f',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Button to apply the changes and perform the split\n",
    "apply_button = widgets.Button(\n",
    "    description='Apply Changes',\n",
    "    button_style='info',\n",
    "    tooltip='Click to apply train-test split'\n",
    ")\n",
    "\n",
    "# Output widget for any textual output or errors\n",
    "output = widgets.Output()\n",
    "\n",
    "def apply_split(b):\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # Splitting the dataset\n",
    "        try:\n",
    "            # Assign the last column as the target and the rest as features\n",
    "            X = data.iloc[:, :-1]\n",
    "            y = data.iloc[:, -1]\n",
    "            # Split the data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=1 - split_slider.value, random_state=42\n",
    "            )\n",
    "            print(f\"Data split into {split_slider.value*100}% training and {100 - split_slider.value*100}% testing.\")\n",
    "            # Optional: Output shapes of the splits\n",
    "            print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "            print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "apply_button.on_click(apply_split)\n",
    "\n",
    "# Display the widgets\n",
    "display(split_slider, apply_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df873ba9",
   "metadata": {},
   "source": [
    "### Data Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7651f-3ed3-466e-b9c4-a6428968ff4f",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to fit and train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63723e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Assume data is loaded as before and split into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Widgets for Linear Regression hyperparameters\n",
    "fit_intercept_toggle = widgets.ToggleButton(\n",
    "    value=True,\n",
    "    description='Fit Intercept',\n",
    "    tooltip='Toggle whether to calculate the intercept for this model'\n",
    ")\n",
    "\n",
    "# Button to train the model and make predictions\n",
    "train_button = widgets.Button(\n",
    "    description='Train and Predict',\n",
    "    button_style='info',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to train the model and predict'\n",
    ")\n",
    "\n",
    "# Output widget for results\n",
    "output = widgets.Output()\n",
    "\n",
    "def train_and_predict(b):\n",
    "    global y_pred\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        try:\n",
    "            # Model initialization\n",
    "            model = LinearRegression(fit_intercept=fit_intercept_toggle.value)\n",
    "            \n",
    "            # Data scaling (optional, uncomment if normalization is needed)\n",
    "            # scaler = StandardScaler()\n",
    "            # X_train_scaled = scaler.fit_transform(X_train)\n",
    "            # X_test_scaled = scaler.transform(X_test)\n",
    "            # Use X_train_scaled and X_test_scaled for training and predictions\n",
    "            \n",
    "            # Training the model\n",
    "            model.fit(X_train, y_train)  # Replace X_train with X_train_scaled if using StandardScaler\n",
    "            \n",
    "            # Making predictions\n",
    "            y_pred = model.predict(X_test)  # Replace X_test with X_test_scaled if using StandardScaler\n",
    "            \n",
    "            # Evaluating the model\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            print(f'Model trained with fit_intercept={fit_intercept_toggle.value}')\n",
    "            print(f'Mean Squared Error: {mse}')\n",
    "            print(f'R2 Score: {r2}')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "train_button.on_click(train_and_predict)\n",
    "\n",
    "# Display the widgets and output\n",
    "widgets.VBox([fit_intercept_toggle, train_button, output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477f944-da8d-4545-8b13-4ab86bd8b855",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to visualize actual vs predicted values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60b754",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Assuming y_test and y_pred are available\n",
    "def plot_predictions_vs_actual(y_test, y_pred):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.title('Predictions vs Actual Data')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "\n",
    "    # Plotting a line of perfect prediction\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)  # Black dashed line for perfect prediction\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the actual data and predictions\n",
    "plot_predictions_vs_actual(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501a56e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "home-nav"
    ]
   },
   "source": [
    "### <center>[üè† Home](../../../../welcomePage.ipynb)</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
