{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f094d36",
   "metadata": {
    "tags": [
     "auto-generated-toc"
    ]
   },
   "source": [
    "## Table of Contents\n",
    "- [Model](#Model)\n",
    "  - [XGBoost (eXtreme Gradient Boosting)](#XGBoost-%28eXtreme-Gradient-Boosting%29)\n",
    "  - [Concept](#Concept)\n",
    "  - [Key Features](#Key-Features)\n",
    "  - [Hyperparameters](#Hyperparameters)\n",
    "  - [Applications](#Applications)\n",
    "- [Implementation](#Implementation)\n",
    "  - [XGBoost](#XGBoost)\n",
    "- [üè† Home](../../../../welcomePage.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9633895",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df1756-726e-4160-870e-ae38815afccb",
   "metadata": {},
   "source": [
    "## XGBoost (eXtreme Gradient Boosting)\n",
    "\n",
    "**XGBoost (eXtreme Gradient Boosting)** is an advanced implementation of gradient boosting that is specifically designed to be highly efficient, flexible, and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way.\n",
    "\n",
    "## Concept\n",
    "\n",
    "The core XGBoost algorithm is an ensemble method that sequentially builds models, and it corrects its own mistakes in the previous steps, enhancing the performance of the ensemble. XGBoost improves upon the base Gradient Boosting Machine (GBM) framework through systems optimization and algorithmic enhancements.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Regularization:** Includes both L1 and L2 regularization which helps in reducing overfitting.\n",
    "- **Handling Sparse Data:** Has built-in handling of missing data values.\n",
    "- **Tree Pruning:** XGBoost makes splits up to the max depth specified and then starts pruning the tree backwards and removes splits beyond which there is no positive gain.\n",
    "- **Built-in Cross-Validation:** XGboost allows user to run a cross-validation at each iteration of the boosting process.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "Some of the key hyperparameters in XGBoost include:\n",
    "- **learning_rate:** Step size shrinkage used to prevent overfitting. Range is [0,1].\n",
    "- **max_depth:** Determines how deeply each tree is allowed to grow during any boosting round.\n",
    "- **subsample:** Percentage of samples used per tree. Low value can lead to underfitting.\n",
    "- **colsample_bytree:** Percentage of features used per tree. High value can lead to overfitting.\n",
    "- **n_estimators:** Number of trees you want to build.\n",
    "- **objective:** Specifies the learning task and the corresponding learning objective or a custom objective function to be used.\n",
    "\n",
    "## Applications\n",
    "\n",
    "XGBoost has become the algorithm of choice for many winning teams of machine learning competitions. It has been successfully used in:\n",
    "- Predictive modeling competitions,\n",
    "- Ranking problems like advertisement ranking,\n",
    "- Classical classification and regression problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdcf492",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b816a8f6",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf91b1-0227-4d3a-a087-544cf6e21c74",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to visualize the decision boundary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18b946",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries are imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a554417-d6a3-44c0-9b03-1da8de7f0947",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e5529-b0b5-4248-b032-d54e602b6fcb",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856493dc-ffcf-4e80-bbe7-392667a6d182",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# List all .csv and Excel files in the current directory\n",
    "supported_extensions = ['.csv', '.xlsx', '.xls']\n",
    "files = [f for f in os.listdir('./data/') if any(f.endswith(ext) for ext in supported_extensions)]\n",
    "\n",
    "# Create a dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=files,\n",
    "    description='Files:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a button widget\n",
    "button = widgets.Button(\n",
    "    description='Select',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to select file',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Output widget to display messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_file = dropdown.value\n",
    "        global data\n",
    "        if selected_file.endswith('.csv'):\n",
    "            data = pd.read_csv('./data/'+selected_file)\n",
    "        elif selected_file.endswith(('.xlsx', '.xls')):\n",
    "            data = pd.read_excel('./data/'+selected_file)\n",
    "        print(f\"File '{selected_file}' uploaded as data.\")\n",
    "\n",
    "# Attach the function to the button widget\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the dropdown, button widgets, and initial message within the output widget\n",
    "with output:\n",
    "    print(\"Please select a file from the dropdown and click 'Select'.\")\n",
    "display(output)\n",
    "display(dropdown)\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f0a2c-f216-40c1-ba9c-c3bfe786ea29",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to display the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d46da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(data.head())\n",
    "print(\"Loading pair plot, please wait...\")\n",
    "sns.pairplot(data=data,hue=data.columns[-1],diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbfbed-273b-4f81-b518-0c22eec7d87e",
   "metadata": {},
   "source": [
    "### Select Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2299aee-6031-4bc4-8806-be1c0f13e11c",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to specify the target column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33609b5a-997b-410e-9fbc-f9af1a4ecd12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Dropdown widget for column selection\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=data.columns.tolist(),\n",
    "    value=data.columns[0],\n",
    "    description='Select Column:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '200px'}\n",
    ")\n",
    "\n",
    "# Create a Button widget\n",
    "button = widgets.Button(\n",
    "    description='Select',\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to select the target column as the last column',\n",
    "    icon='check'  # FontAwesome icon names (without 'fa-')\n",
    ")\n",
    "\n",
    "# Create an Output widget for displaying messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click that rearranges the DataFrame\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        global data\n",
    "        # Get the selected column name\n",
    "        selected_column = dropdown.value\n",
    "        # Reorder the DataFrame columns\n",
    "        new_columns = [col for col in data.columns if col != selected_column] + [selected_column]\n",
    "        data = data[new_columns]\n",
    "        print(f\"Column '{selected_column}' has been moved to the last position.\")\n",
    "\n",
    "# Link the button click event to the function\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the widgets and output\n",
    "display(widgets.VBox([dropdown, button, output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec773ab-9f12-41b5-af07-2959affd35b2",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889db060-bae2-4665-8cde-e990ad14fc2d",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to handle nulls, process categorical values, and normalize data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe3101-9700-4d62-a9cd-82ace4a949ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Widgets for selecting operations and methods\n",
    "fill_method_dropdown = widgets.Dropdown(\n",
    "    options=[('None', None), ('Zero', 'zero'), ('Mean', 'mean'), ('Median', 'median')],\n",
    "    value=None,\n",
    "    description='Fill Method:',\n",
    ")\n",
    "\n",
    "remove_nulls_checkbox = widgets.Checkbox(value=False, description='Remove Nulls')\n",
    "encode_categorical_checkbox = widgets.Checkbox(value=False, description='Encode Categorical')\n",
    "normalize_data_checkbox = widgets.Checkbox(value=False, description='Normalize Data')\n",
    "\n",
    "# Button to apply selected operations\n",
    "apply_button = widgets.Button(description='Apply All', button_style='info')\n",
    "\n",
    "# Button to display data\n",
    "show_data_button = widgets.Button(description='Show Data')\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def apply_operations():\n",
    "    global data\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # Fill missing values based on selected method\n",
    "        if fill_method_dropdown.value:\n",
    "            if fill_method_dropdown.value == 'zero':\n",
    "                data = data.fillna(0)\n",
    "            elif fill_method_dropdown.value in ['mean', 'median']:\n",
    "                # Apply fill method only to numeric columns\n",
    "                numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "                for column in numeric_cols:\n",
    "                    if data[column].sum() != 0:\n",
    "                        if fill_method_dropdown.value == 'mean':\n",
    "                            mean_value = data[column].mean()\n",
    "                            data[column] = data[column].fillna(mean_value)\n",
    "                        elif fill_method_dropdown.value == 'median':\n",
    "                            median_value = data[column].median()\n",
    "                            data[column] = data[column].fillna(median_value)\n",
    "            print(f\"Missing values filled with {fill_method_dropdown.value}.\")\n",
    "\n",
    "        if remove_nulls_checkbox.value:\n",
    "            data = data.dropna()  # Remove remaining null values\n",
    "            print(\"Remaining null values removed.\")\n",
    "        if encode_categorical_checkbox.value:\n",
    "            # Apply label encoding to categorical columns\n",
    "            label_encoder = LabelEncoder()\n",
    "            categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "            for col in categorical_cols:\n",
    "                data[col] = label_encoder.fit_transform(data[col].astype(str))\n",
    "            print(\"Categorical data encoded using label encoding.\")\n",
    "        if normalize_data_checkbox.value:\n",
    "            # Normalize numeric columns using MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "            data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "            print(\"Data normalized.\")\n",
    "\n",
    "def show_data(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        display(data.head())  # Show the head of the DataFrame\n",
    "\n",
    "apply_button.on_click(lambda b: apply_operations())\n",
    "show_data_button.on_click(show_data)\n",
    "\n",
    "# Layout the widgets\n",
    "widgets.VBox([\n",
    "    widgets.Label('Select Fill Method and Operations:'),\n",
    "    fill_method_dropdown,\n",
    "    remove_nulls_checkbox,\n",
    "    encode_categorical_checkbox,\n",
    "    normalize_data_checkbox,\n",
    "    apply_button,\n",
    "    show_data_button,\n",
    "    output\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975aee16",
   "metadata": {},
   "source": [
    "### Split data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4fb52-e88f-4248-8f05-7eab0bf44044",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to split the data into training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba776f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "X = data.iloc[:, :-1]  # all rows, all columns except the last one\n",
    "y = data.iloc[:, -1]   # all rows, just the last column\n",
    "# Function to split data and display the shape of the splits\n",
    "\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "\n",
    "def split_data(button):\n",
    "    global X_train, X_test, y_train, y_test  # Declare the use of global variables\n",
    "    test_size = test_size_slider.value\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Display the output\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Create output widget\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# Create slider for test size\n",
    "test_size_slider = widgets.FloatSlider(\n",
    "    value=0.25,  # Default split 75%-25%\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.05,\n",
    "    description='Test Size:',\n",
    "    readout_format='.2f',  # Display format\n",
    ")\n",
    "\n",
    "# Create an Apply button\n",
    "apply_button = widgets.Button(description=\"Apply Changes\")\n",
    "\n",
    "# Set up button click event to trigger the data split\n",
    "apply_button.on_click(split_data)\n",
    "\n",
    "# Organize widgets in a vertical box\n",
    "widgets_box = widgets.VBox([test_size_slider, apply_button, out])\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c5c738",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b4a46-77d2-4531-ad0d-7fec765bb5a0",
   "metadata": {},
   "source": [
    "### Key Parameters in XGBoost\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is a powerful and efficient implementation of the gradient boosting framework. The performance and speed of XGBoost make it a popular choice among data scientists. Key parameters such as `learning_rate`, `n_estimators`, and `max_depth` play crucial roles in model training and accuracy:\n",
    "\n",
    "#### 1. Learning Rate (`learning_rate`)\n",
    "\n",
    "The `learning_rate`, also known as `eta`, controls how quickly the model fits the residual error using additional base learners. A lower value makes the model robust to the specific characteristics of the tree but takes longer to compute as more trees are needed. A higher learning rate can lead to rapid convergence but risk overfitting if too high. Typically, a smaller learning rate with more trees could increase accuracy but also computational cost.\n",
    "\n",
    "#### 2. Number of Estimators (`n_estimators`)\n",
    "\n",
    "This parameter defines the number of gradient boosted trees to fit. It is equivalent to the number of boosting rounds. More trees can improve accuracy but also risk overfitting, especially when the learning rate is high. It is crucial to balance the number of estimators with the learning rate to achieve the best performance. This parameter interacts with the learning rate (`learning_rate`): a lower learning rate often requires more trees to model all relevant relations and interactions adequately.\n",
    "\n",
    "#### 3. Maximum Depth (`max_depth`)\n",
    "\n",
    "`max_depth` sets the maximum depth of each tree. Deeper trees can model more complex patterns by creating more specific rules (i.e., more splits in the decision trees). However, very deep trees can lead to overfitting, especially in noisy data. Limiting the tree depth is a common technique to enhance generalization. \n",
    "\n",
    "Properly tuning these parameters is key to building a high-performing XGBoost model. They control the model's complexity and its ability to generalize on unseen data. Overfitting and underfitting are significant concerns that need balancing when adjusting these parameters, often requiring cross-validation to optimize effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640c64a-2a10-49f8-8542-ebe38d667c4b",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f0083",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Assuming X_train and y_train, X_test, y_test are already defined\n",
    "# Assuming y_train and y_test contain string labels\n",
    "\n",
    "# Encode target labels with value between 0 and n_classes-1\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the training and test data\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Initialize global variables for XGBoost classifier and predictions\n",
    "xgb_clf = None\n",
    "y_pred = None\n",
    "\n",
    "# Function to train XGBoost and print accuracy\n",
    "def train_xgb(button):\n",
    "    global learning_rate, n_estimators, max_depth, xgb_clf, y_pred\n",
    "    xgb_clf = xgb.XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth, use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb_clf.fit(X_train_std, y_train_encoded)\n",
    "    train_accuracy = xgb_clf.score(X_train_std, y_train_encoded)\n",
    "    test_accuracy = xgb_clf.score(X_test_std, y_test_encoded)*100\n",
    "    y_pred = xgb_clf.predict(X_test_std)\n",
    "    y_pred = label_encoder.inverse_transform(y_pred)  # Decode the predictions to original labels\n",
    "    # Display the output\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        print(f'The accuracy of the xgb classifier is {test_accuracy:.1f}% on test data')\n",
    "# Create output widget\n",
    "out = widgets.Output()\n",
    "\n",
    "# Function to update XGBoost parameters\n",
    "def update_params(change):\n",
    "    global learning_rate, n_estimators, max_depth\n",
    "    learning_rate = learning_rate_slider.value\n",
    "    n_estimators = n_estimators_slider.value\n",
    "    max_depth = max_depth_slider.value\n",
    "\n",
    "# Create sliders for XGBoost parameters\n",
    "learning_rate_slider = widgets.FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.01,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Learning Rate:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '200px'}\n",
    ")\n",
    "\n",
    "n_estimators_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=500,\n",
    "    step=10,\n",
    "    description='N Estimators:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '200px'}\n",
    ")\n",
    "\n",
    "max_depth_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Max Depth:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '200px'}\n",
    ")\n",
    "\n",
    "# Create a button to train the model\n",
    "train_button = widgets.Button(description=\"Train\")\n",
    "\n",
    "# Link parameter widgets to the update_params function\n",
    "learning_rate_slider.observe(update_params, 'value')\n",
    "n_estimators_slider.observe(update_params, 'value')\n",
    "max_depth_slider.observe(update_params, 'value')\n",
    "\n",
    "# Set up button click event to trigger the data split\n",
    "train_button.on_click(train_xgb)\n",
    "\n",
    "# Organize widgets in a vertical box\n",
    "widgets_box = widgets.VBox([learning_rate_slider, n_estimators_slider, max_depth_slider, train_button, out])\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24378088-ed4c-446b-b0e0-152380ea6573",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to display the confusion matrix and the classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20521f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f2d6a-939c-4766-98a2-8c3edf1257b8",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac3e40-c565-417c-9677-cfaea21d5b29",
   "metadata": {},
   "source": [
    "In classification tasks, the <span style=\"color:red\">red</span> and <span style=\"color:blue\">blue</span> areas typically represent different classes or categories. The <span style=\"color:red\">red</span> area signifies regions where the classifier predicts one class, while the <span style=\"color:blue\">blue</span> area represents regions where it predicts another class, based on the features of the data points in those regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89005387-2079-4d21-8446-ddbde7e768bf",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to visualize the decision boundary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd3f33-1912-4978-977e-2f81d4eb6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, label_encoder, feature1, feature2, resolution=0.02):\n",
    "    X = X[[feature1, feature2]]  # Take the selected features for visualization\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ['red', 'blue', 'lightgreen', 'gray', 'cyan']\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "    x2_min, x2_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X.loc[y == cl, feature1], y=X.loc[y == cl, feature2],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=label_encoder.inverse_transform([cl])[0])\n",
    "\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.title('XGBoost Classification with Decision Boundaries')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "# Encoding the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dropdowns for selecting features\n",
    "feature_selector1 = widgets.Dropdown(\n",
    "    options=X.columns,\n",
    "    description='X Axis:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "feature_selector2 = widgets.Dropdown(\n",
    "    options=X.columns,\n",
    "    description='Y Axis:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Plot\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        feature1 = feature_selector1.value\n",
    "        feature2 = feature_selector2.value\n",
    "        \n",
    "        if feature1 and feature2:\n",
    "            xgb_model = XGBClassifier()\n",
    "            xgb_model.fit(X_train[[feature1, feature2]], y_train)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plot_decision_regions(X_test, y_test, xgb_model, label_encoder, feature1, feature2)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Please select both features\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(feature_selector1, feature_selector2, button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28775c12-4e66-4673-8b08-0c6a81afa451",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "home-nav"
    ]
   },
   "source": [
    "### <center>[üè† Home](../../../../welcomePage.ipynb)</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
