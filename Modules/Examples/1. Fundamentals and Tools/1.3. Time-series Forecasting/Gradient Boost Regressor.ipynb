{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89e2d19",
   "metadata": {
    "tags": [
     "auto-generated-toc"
    ]
   },
   "source": [
    "## Table of Contents\n",
    "- [Gradient Boost Regressor](#Gradient-Boost-Regressor)\n  - [Concept](#Concept)\n  - [How It Works](#How-It-Works)\n  - [Key Parameters](#Key-Parameters)\n  - [Advantages](#Advantages)\n  - [Applications](#Applications)\n- [Implementation](#Implementation)\n- [üè† Home](../../../../welcomePage.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4caeb-a06a-402a-83e6-2625d7f1871b",
   "metadata": {},
   "source": [
    "# Gradient Boost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21eb3c1-0530-4bd7-929c-fce3a30f5730",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Gradient Boosting Regressor** is a powerful ensemble machine learning algorithm that builds models in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.\n",
    "\n",
    "## Concept\n",
    "\n",
    "Gradient Boosting involves three main components:\n",
    "1. **Loss Function to be optimized:** Gradient Boosting is a flexible method that can be used on differentiable loss functions. For regression tasks, it typically uses squared error or absolute error.\n",
    "2. **Weak Learner to make predictions:** Gradient Boosting uses decision trees as the weak learners. Trees are added one at a time, and existing trees in the model are not changed.\n",
    "3. **Additive Model to add weak learners:** Trees are added one at a time, and gradient descent is used to minimize the loss when adding trees.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "The algorithm builds the model in a stage-wise fashion:\n",
    "1. Fit a decision tree to the data, e.g., predict the mean of the target variable.\n",
    "2. Apply the decision tree to the data and calculate the error residuals.\n",
    "3. Fit a new decision tree to the residuals from the previous step.\n",
    "4. Add this new decision tree into the ensemble, update the model.\n",
    "5. Repeat steps 2-4 until a specified number of trees have been added or the loss changes minimally on adding a new tree.\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    "- $n_{\\text{estimators}}$: The number of boosting stages to perform. More stages increase the model complexity.\n",
    "- $\\text{learning\\_rate}$: Shrinks the contribution of each tree by the learning rate. There is a trade-off between learning rate and number of stages.\n",
    "- $\\text{max\\_depth}$: Limits the number of nodes in the decision trees. Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "- $\\text{min\\_samples\\_split}$: The minimum number of samples required to split an internal node.\n",
    "- $\\text{min\\_samples\\_leaf}$: The minimum number of samples required to be at a leaf node.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- Can handle heterogeneous features (numeric and categorical).\n",
    "- Robust to outliers in output space (via robust loss functions).\n",
    "- Provides predictive score distributions by way of quantile regression.\n",
    "\n",
    "## Applications\n",
    "\n",
    "Gradient Boosting can be used for:\n",
    "- Demand forecasting in retail,\n",
    "- Price prediction in real estate,\n",
    "- Predicting customer lifetime value in various industries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732670c9-6652-47ac-85f8-9b230801337b",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab76a44-2ba6-4c72-a5ba-3c8013a7e5c2",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a6bfb-1fc4-4123-97fc-a5551b2bf88c",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to import libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab575897-5411-47d3-916c-e9a933b41d16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries are imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603dfa4-0574-4c16-a29a-9d7ac013e13c",
   "metadata": {},
   "source": [
    "### Import and show Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92652580-48f1-4e60-bb0e-502310662304",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a59e8-9209-4d78-92a2-1f5517e89a06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# List all .csv and Excel files in the current directory\n",
    "supported_extensions = ['.csv', '.xlsx', '.xls']\n",
    "files = [f for f in os.listdir('./Data') if any(f.endswith(ext) for ext in supported_extensions)]\n",
    "\n",
    "# Create a dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=files,\n",
    "    description='Files:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a button widget\n",
    "button = widgets.Button(\n",
    "    description='Select',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to select file',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Output widget to display messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_file = dropdown.value\n",
    "        global data\n",
    "        if selected_file.endswith('.csv'):\n",
    "            data = pd.read_csv(\"./Data/\" +selected_file)\n",
    "        elif selected_file.endswith(('.xlsx', '.xls')):\n",
    "            data = pd.read_excel(\"./Data/\" +selected_file)\n",
    "        print(f\"File '{selected_file}' uploaded as data.\")\n",
    "\n",
    "# Attach the function to the button widget\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the dropdown, button widgets, and initial message within the output widget\n",
    "with output:\n",
    "    print(\"Please select a file from the dropdown and click 'Select'.\")\n",
    "display(output)\n",
    "display(dropdown)\n",
    "display(button)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d75e7c-d7be-44e4-b3b5-f5717b68fe40",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to display the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f8275-8424-4741-87be-9a8f03b64b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(data.head())\n",
    "print (\"The data is composed of \", data.shape[0], \" rows and \", data.shape[1], \" columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb45030-83ad-4741-972d-4c93da7d9361",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58e4e3-f428-46bd-93a2-26a973474576",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to specify the target column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067b7dd-f274-4820-82c6-b5e60344ac45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Dropdown widget for column selection\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=data.columns.tolist(),\n",
    "    value=data.columns[0],\n",
    "    description='Select Target Column:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '200px'}\n",
    ")\n",
    "\n",
    "# Create a Button widget\n",
    "button = widgets.Button(\n",
    "    description='Select',\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to select the target column as the last column',\n",
    "    icon='check'  # FontAwesome icon names (without 'fa-')\n",
    ")\n",
    "\n",
    "# Create an Output widget for displaying messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click that rearranges the DataFrame\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        global data\n",
    "        # Get the selected column name\n",
    "        selected_column = dropdown.value\n",
    "        # Reorder the DataFrame columns\n",
    "        new_columns = [col for col in data.columns if col != selected_column] + [selected_column]\n",
    "        data = data[new_columns]\n",
    "        print(f\"Column '{selected_column}' has been moved to the last position.\")\n",
    "\n",
    "# Link the button click event to the function\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the widgets and output\n",
    "display(widgets.VBox([dropdown, button, output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8db1e-b0a7-4faa-8d54-904d9e7a2ca9",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to create a lagged target column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5eae02-6b01-4bf6-be71-9b4b2be4c605",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "target = data.columns[-1]\n",
    "data['Target_Lag'] = data.iloc[:, -1].shift(1)\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9fda3-19cc-4104-8e05-1ca71cba5fac",
   "metadata": {},
   "source": [
    "### Predict Bead Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118955ba-5eb0-4d00-8ac9-840caf1adcdb",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "##### Number of Estimators\n",
    "The number of estimators refers to the number of boosting stages to be run, which is equivalent to the number of trees in the model. This parameter controls how many weak learners (typically decision trees) are added to the model sequentially. Each new tree is trained to correct the errors made by the combined ensemble of all previous trees. A higher number of estimators generally increases the complexity of the model and can lead to better performance, up to a point. However, too many estimators can lead to overfitting. By adding more estimators, the model can learn more intricate patterns in the data, improving prediction accuracy.\n",
    "\n",
    "##### Maximum Depth\n",
    "The maximum depth of the individual trees sets the maximum number of levels in each decision tree. This parameter limits how deep the trees can grow. Deeper trees can capture more detailed interactions in the data but can also lead to overfitting if they become too complex. Limiting the maximum depth helps prevent overfitting by controlling the complexity of the trees, while a suitable maximum depth allows the model to capture important interactions between features without becoming too complex.\n",
    "\n",
    "##### Learning Rate\n",
    "The learning rate is the step size at which the model learns, shrinking the contribution of each tree by a factor of the learning rate. This parameter scales the contribution of each new tree added to the ensemble. A smaller learning rate requires more trees to model the data effectively but can lead to better generalization. A lower learning rate generally improves the model's performance by making it learn more slowly and steadily, thus preventing overfitting. However, it requires more estimators to achieve the same level of performance. Balancing the learning rate with the number of estimators is crucial for building a robust model that generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abeb6e-0754-4dd8-95d5-407cbc6ea68f",
   "metadata": {},
   "source": [
    "**Press ‚ñ∂ to specify independent variables, train/test split, and the model parameter and to forecast the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8be3f-b76c-45cd-985d-14dc69879864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define widgets with adjusted layout\n",
    "index_range_slider = widgets.IntRangeSlider(\n",
    "    value=[0, min(7000, len(data))],\n",
    "    min=0,\n",
    "    max=len(data),\n",
    "    step=1,\n",
    "    description='Index Range:',\n",
    "    layout=widgets.Layout(width='600px'),  # Increase width for better readability\n",
    "    style={'description_width': '150px'},  # Increase description width\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "feature_select = widgets.SelectMultiple(\n",
    "    options=tuple(col for col in data.columns if col != target),\n",
    "    value=tuple(col for col in data.columns if col != target),\n",
    "    description='Features:',\n",
    "    layout=widgets.Layout(width='600px', height='180px'),  # Increase width and height\n",
    "    style={'description_width': '150px'},  # Increase description width\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "train_size_slider = widgets.IntSlider(\n",
    "    value=80,\n",
    "    min=50,\n",
    "    max=95,\n",
    "    step=1,\n",
    "    description='Train %:',\n",
    "    layout=widgets.Layout(width='600px'),  # Increase width\n",
    "    style={'description_width': '150px'},  # Increase description width\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Gradient Boosting parameter sliders\n",
    "n_estimators_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=500,\n",
    "    step=10,\n",
    "    description='Number of Estimators:',\n",
    "    layout=widgets.Layout(width='600px'),\n",
    "    style={'description_width': '160px'},\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "max_depth_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Maximum Depth:',\n",
    "    layout=widgets.Layout(width='600px'),\n",
    "    style={'description_width': '150px'},\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "learning_rate_slider = widgets.FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.01,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description='Learning Rate:',\n",
    "    layout=widgets.Layout(width='600px'),\n",
    "    style={'description_width': '150px'},\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "apply_button = widgets.Button(description=\"Apply Changes\", layout=widgets.Layout(width='800px'))\n",
    "\n",
    "# Define the function to apply changes and update the plots\n",
    "def apply_changes(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Extract the parameters from widgets\n",
    "        index_range = index_range_slider.value\n",
    "        selected_features = list(feature_select.value)\n",
    "        train_size_pct = train_size_slider.value / 100\n",
    "        n_estimators = n_estimators_slider.value\n",
    "        max_depth = max_depth_slider.value\n",
    "        learning_rate = learning_rate_slider.value\n",
    "        \n",
    "        # Slice the data\n",
    "        df = data[index_range[0]:index_range[1]]\n",
    "        \n",
    "\n",
    "        X = df[selected_features]\n",
    "        y = df[target]\n",
    "        \n",
    "        # Train-test split\n",
    "        train_size = int(len(df) * train_size_pct)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        # Train the model\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        display(HTML(f'<b>Mean Squared Error: {mse:.5f}</b>'))  # Display MSE in bold\n",
    "        \n",
    "        # Plot predicted vs actual\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(y_train.index, y_train, label='Training', color='green')\n",
    "        plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "        plt.plot(y_test.index, y_pred, label='Predicted', color='red', linestyle='--')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(target)\n",
    "        plt.title('Actual vs Predicted '+target)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate loss for each point\n",
    "        pointwise_mse_loss = (y_test - y_pred) ** 2\n",
    "        \n",
    "        # Plot the pointwise loss\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "        plt.plot(y_test.index, y_pred, label='Predicted', color='red', linestyle='--')\n",
    "        plt.plot(y_test.index, pointwise_mse_loss, label='Pointwise MSE Loss', color='orange')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.title('Pointwise MSE Loss of Predicted vs Actual '+target)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Link the apply button to the function\n",
    "apply_button.on_click(apply_changes)\n",
    "\n",
    "# Display the widgets and the output area\n",
    "output = widgets.Output()\n",
    "\n",
    "display(index_range_slider, feature_select, train_size_slider, n_estimators_slider, max_depth_slider, learning_rate_slider, apply_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da3a3a-59c4-4b62-a906-21a48e22cdb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "home-nav"
    ]
   },
   "source": [
    "### <center>[üè† Home](../../../../welcomePage.ipynb)</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
