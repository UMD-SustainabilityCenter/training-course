{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b30aac",
   "metadata": {
    "tags": [
     "auto-generated-toc"
    ]
   },
   "source": [
    "## Table of Contents\n",
    "- [B3 Model-Based Enterprise-Engineering (MBE)](#B3-Model-Based-Enterprise-Engineering-%28MBE%29)\n",
    "  - [3.1 Advanced MBE Concepts](#3.1-Advanced-MBE-Concepts)\n",
    "  - [3.2 Interoperability & Standards in MBE](#3.2-Interoperability-%26-Standards-in-MBE)\n",
    "  - [3.3 Automation & AI in MBE](#3.3-Automation-%26-AI-in-MBE)\n",
    "  - [3.4 Example: Hands-on Excercise for Predictive Maintenance</font>](#3.4-Example%3A-Hands-on-Excercise-for-Predictive-Maintenance%3C/font%3E)\n",
    "  - [3.5 Example 2: Conceptual Concept for Predictive Maintenance of Aircraft Gas Turbine Engines](#3.5-Example-2%3A-Conceptual-Concept-for-Predictive-Maintenance-of-Aircraft-Gas-Turbine-Engines)\n",
    "  - [3.6 Cybersecurity & Data Integrity in MBE](#3.6-Cybersecurity-%26-Data-Integrity-in-MBE)\n",
    "  - [3.7 Large Scale Real-World Applications](#3.7-Large-Scale-Real-World-Applications)\n",
    "  - [3.8 Automotive & Manufacturing Applications](#3.8-Automotive-%26-Manufacturing-Applications)\n",
    "  - [3.9 **Conclusion & Next Steps**](#3.9-%2A%2AConclusion-%26-Next-Steps%2A%2A)\n",
    "- [üè† Home](../../welcomePage.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21df3db4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# B3 Model-Based Enterprise-Engineering (MBE)\n",
    "Historically, the industry relied on drawings to communicate manufacturing components and systems requirements. The decentralization of manufacturing systems has amplified the challenge of collecting and communicating the product and process specifications needed to make decisions about design, production, and supply chain tasks while delivering products to market. Moving away from a reliance on drawings, MBE leverages computer-based technology to design, price, and manufacture items in a digital-centric environment. MBE is a fully integrated and collaborative environment built on detailed 3D product definitions shared across the enterprise to enable rapid, seamless, and affordable deployment of products from concept to disposal.  The foundational elements of MBE are A single digital master data set containing the 3D model and all needed product data in a managed, secure, and controlled environment that supports maximum data reuse for all acquisition, maintenance, and operations aspects.\n",
    "\n",
    "At the Black Belt level, the focus shifts from understanding and adopting MBE principles to **mastering advanced integration, optimization, and automation techniques**. This module explores the **full-scale deployment of MBE**, emphasizing **interoperability, automation, AI-driven analytics, and real-world implementation challenges**.\n",
    "\n",
    "## 3.1 Advanced MBE Concepts\n",
    "\n",
    "### <font color = '#646464'>3.1.1 Enterprise-Wide Digital Thread Implementation</font>\n",
    "**Goal:** Establish a comprehensive, end-to-end connected ecosystem that spans design, manufacturing, and sustainment processes, ensuring seamless information flow throughout the product lifecycle.\n",
    "\n",
    "- **End-to-End Connected Ecosystem:** The digital thread concept connects disparate systems and teams by enabling the flow of data across the entire product lifecycle‚Äîfrom initial design to final sustainment. By ensuring this connectivity, organizations can better understand product performance, identify inefficiencies, and enhance decision-making.\n",
    "\n",
    "- **Using PLM (Product Lifecycle Management) and ERP (Enterprise Resource Planning) Systems for Seamless Data Flow:** Product Lifecycle Management (PLM) and Enterprise Resource Planning (ERP) systems play a crucial role in supporting the digital thread by providing centralized repositories for data and ensuring that product information is available across different stages of the lifecycle. PLM systems manage the product's design, manufacturing, and maintenance data, while ERP systems provide support for planning, procurement, inventory management, and production processes. The integration of both systems ensures a smooth and consistent data flow between different teams and functions.\n",
    "\n",
    "- **Case Study: Boeing‚Äôs Implementation of Digital Thread:** Boeing is an example of a company that has successfully implemented a digital thread across its operations. The company uses digital twins and simulation models to track and optimize the performance of their aircraft throughout the entire lifecycle. This digital thread connects design, production, and maintenance processes, allowing for real-time performance monitoring, faster issue identification, and better resource management. Boeing‚Äôs use of the digital thread not only ensures that engineering and manufacturing teams are working with the most up-to-date information but also improves the sustainment phase by providing predictive maintenance insights based on real-world data.\n",
    "\n",
    "<center><img src=\"https://www.boeingsuppliers.com/content/dam/microsites/static/supplier/suppliers/doingbiz_redesign/images/section/MBE_DigitalThread.png\" alt=\"Alt text\" /></center>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color = '#646464'>3.1.2 Model-Based Systems Engineering (MBSE) at Scale</font>\n",
    "**Goal:** Expand Model-Based Systems Engineering (MBSE) practices beyond just product design, applying them to the full lifecycle management of complex systems, and ensuring cross-disciplinary integration.\n",
    "\n",
    "- **Expanding MBSE Beyond Product Design to Full Lifecycle Management:** MBSE traditionally focuses on the design phase of the product lifecycle, but its applications can be extended to include the entire lifecycle‚Äîfrom concept development and design to manufacturing, testing, and sustainment. The goal is to use MBSE to not only improve the design phase but also optimize each subsequent phase by integrating real-time data and feedback into system models.\n",
    "\n",
    "- **Integrating Multi-Disciplinary Models (Mechanical, Electrical, Software, etc.):** A key feature of MBSE is its ability to integrate multi-disciplinary models. In the context of complex systems, models from various domains (e.g., mechanical, electrical, software, etc.) need to be linked together for better analysis and optimization. For instance, the mechanical design of a system may be linked to its electrical and software models, allowing engineers to analyze the interactions and interdependencies between these disciplines. This integration leads to a more holistic understanding of the system and ensures that all aspects are considered during the development process.\n",
    "\n",
    "- **Tools:** Several tools can support MBSE at scale, including:\n",
    "  - **SysML (Systems Modeling Language):** A standard modeling language used to represent complex system structures and behaviors. SysML is widely used for creating diagrams and models that help describe system functions, architecture, and requirements.\n",
    "  - **Cameo Systems Modeler:** A modeling tool that supports SysML and is used to build, analyze, and manage system models. It allows users to create rich models that can integrate with other tools in the systems engineering workflow.\n",
    "\n",
    "**SysML example**: The diagram below shows both the SysML code and visualization for the structure of a vehicle system that consists of Engine, Transmission, Wheel, Steering, and Chassis. Each of those subsystems can also have its own components. This view is only for the system design; there are other views for requirements, system analysis, implementation, and architecture. \n",
    "\n",
    "\n",
    "<center><img src=\"https://media.licdn.com/dms/image/v2/C4D12AQGooY4AojdsNQ/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1603862142761?e=1746057600&v=beta&t=IQ5ZGOYMc1IC5JURVnQjOS64_bV7aYMOSmorPAe7cv4\" alt=\"Alt text\" /></center>\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Interoperability & Standards in MBE\n",
    "\n",
    "### <font color = '#646464'>3.2.1 Ensuring Interoperability Across Systems</font>\n",
    "**Goal:** To ensure seamless communication and data exchange between different systems used in MBE, including CAD, PLM, and MES, while adhering to common standards that enable interoperability.\n",
    "\n",
    "- **Standards:**\n",
    "    - **ISO 10303 (STEP):** The ISO 10303 standard, commonly known as STEP (Standard for the Exchange of Product model data), is a comprehensive international standard that facilitates the exchange of product data between different systems. STEP provides a method for representing product data (such as 3D models, materials, and assembly information) in a neutral format that can be understood across various platforms, including CAD, PLM, and ERP systems. It is widely used to ensure that data can be shared across disciplines without loss of information.\n",
    "      \n",
    "    - **ANSI QIF (Quality Information Framework):** The ANSI QIF is a standard for representing and exchanging quality-related information in the manufacturing process. It defines a common framework for data related to inspection, verification, and measurement, ensuring that quality data generated during manufacturing can be easily integrated into the broader product lifecycle. ANSI QIF plays a key role in ensuring that the information needed for quality assurance is accurately captured and shared across systems.\n",
    "      \n",
    "    - **ASME Y14.41:** ASME Y14.41 defines the standards for digital product definition data, focusing on the use of 3D models and their integration into product definition documents. This standard provides guidelines on how to represent product design data, including 3D CAD models, and ensures that this information can be seamlessly communicated to downstream manufacturing and quality systems.\n",
    "      \n",
    "- **Bridging Different CAD, PLM, and MES Systems:** One of the key challenges in MBE is ensuring that data can flow smoothly between different software systems that play different roles in the product lifecycle. \n",
    "    - **CAD (Computer-Aided Design):**  \n",
    "      CAD systems are used to create 3D product designs, and often have proprietary file formats that are not easily compatible with other systems.\n",
    "      \n",
    "    - **PLM (Product Lifecycle Management):** PLM systems manage the data and processes associated with the entire product lifecycle, from initial design to end-of-life. PLM systems often store vast amounts of data, including design specifications, bills of materials (BOM), and configuration data, which need to be easily accessible by other systems.\n",
    "      \n",
    "    - **MES (Manufacturing Execution Systems):**  MES systems manage the production processes, such as scheduling, tracking, and optimizing manufacturing activities. Ensuring that the right data from CAD and PLM systems reaches MES is crucial for accurate manufacturing execution.\n",
    "\n",
    "    The key to bridging these systems lies in creating data exchange frameworks based on standard file formats like STEP and QIF, as well as using middleware and integration tools that facilitate communication between these diverse systems. This interoperability ensures that no information is lost, that the systems are synchronized, and that engineers and manufacturers are working with up-to-date data.\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-030-62807-9_7/MediaObjects/506696_1_En_7_Fig3_HTML.png\" alt=\"Alt text\" /></center>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color = '#646464'>3.2.2 Ontology and Semantic Data Models</font>\n",
    "**Goal:** To enhance data integration, retrieval, and analysis in MBE by utilizing semantic data models and graph-based databases that enable AI-driven automation and advanced analytics.\n",
    "\n",
    "- **Using Graph-Based Databases (RDF, OWL, SPARQL) for MBE Data Integration:** Graph-based databases allow for more flexible and dynamic data representation compared to traditional relational databases. These databases are designed to handle complex relationships between data entities, which is particularly useful in MBE where systems and components are highly interconnected.\n",
    "    \n",
    "    - **RDF (Resource Description Framework):**  RDF is a framework for representing data as triples (subject-predicate-object) in a way that can describe relationships between resources. RDF is highly useful for integrating different kinds of data from various MBE tools, such as CAD, PLM, and MES, because it allows different data points to be connected, enabling richer information retrieval and better integration across the lifecycle.\n",
    "      \n",
    "    - **OWL (Web Ontology Language):**  OWL is used to define the types, properties, and relationships of data in a way that makes it machine-readable. In MBE, OWL can be used to build ontologies that define the key entities (e.g., parts, assemblies, materials, manufacturing processes) and their relationships, facilitating better data sharing and understanding across the entire lifecycle.\n",
    "      \n",
    "    - **SPARQL (SPARQL Protocol and RDF Query Language):**  SPARQL is a query language for querying RDF data stores. It allows users to retrieve and manipulate data stored in graph-based formats. In MBE, SPARQL enables complex queries that can combine information from different systems and domains, such as design, manufacturing, and maintenance, into a single query result.\n",
    "\n",
    "- **Enabling AI-Driven Automation and Analytics:** The use of semantic data models and graph-based databases in MBE can provide a rich foundation for AI-driven automation and advanced analytics. \n",
    "    - **Automation:** AI can leverage the interconnected data in a graph database to automate tasks such as design optimization, failure prediction, and real-time manufacturing scheduling. By analyzing relationships and patterns across multiple systems, AI can suggest improvements, automate repetitive tasks, and trigger actions based on real-time data.\n",
    "      \n",
    "    - **Analytics:** The ability to query complex data relationships with SPARQL and model systems using OWL enables more sophisticated data analytics. Engineers can use advanced analytics to uncover hidden insights about product performance, quality, and potential risks. For example, AI could analyze product lifecycle data to predict failure modes or identify inefficiencies in the design or manufacturing process.\n",
    "\n",
    "    - **Example:**  In a manufacturing setting, a graph-based database can integrate design, manufacturing, and operational data, allowing AI to track a product's lifecycle from design to final use. The AI system could analyze this data to predict future failures, optimize resource allocation, and identify potential issues in the manufacturing process before they occur.\n",
    "\n",
    "<center><img src=\"https://www.applyscience.it/wp-content/uploads/2020/09/predictive-maintenance.png\" alt=\"Alt text\" /></center>\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Automation & AI in MBE\n",
    "\n",
    "### <font color = '#646464'>3.3.1 Digital Twin & Simulation-Driven Decision Making\n",
    "**Goal:** To leverage digital twin technology and simulation-driven decision-making to optimize product performance, enhance predictive maintenance, and facilitate real-time monitoring throughout the lifecycle.\n",
    "\n",
    "- **Deploying Digital Twins for Predictive Maintenance & Real-Time Monitoring:** A **Digital Twin** is a digital replica of a physical object or system that is continuously updated with real-time data from sensors embedded in the physical counterpart. Digital twins can be deployed in manufacturing and product operations to predict and prevent failures before they occur.\n",
    "  \n",
    "    - **Predictive Maintenance:** By continuously monitoring the physical system‚Äôs data (such as temperature, vibration, pressure, etc.) and comparing it with the digital model, the digital twin can predict when a part will likely fail or require maintenance. For example, in industrial machinery, a digital twin can predict when a component is nearing the end of its useful life, allowing maintenance teams to schedule repairs proactively and avoid unplanned downtime.\n",
    "    \n",
    "    - **Real-Time Monitoring:** A digital twin can be used to monitor real-time performance data from systems such as machines, vehicles, or even entire production lines. This allows operators to track system health and performance in real-time, identifying deviations from expected behavior and adjusting parameters or processes before an issue escalates.\n",
    "\n",
    "    - **Optimized Asset Management:** Digital twins help organizations optimize asset management by providing insights into the performance and condition of physical assets. By analyzing historical data, manufacturers can optimize asset utilization, minimize downtime, and extend the lifespan of expensive equipment.\n",
    "\n",
    "- **Simulation-Based What-If Analysis for Design and Manufacturing Optimization:** Simulation tools allow engineers to run ‚Äúwhat-if‚Äù scenarios to test different design or manufacturing decisions before committing to them. This enables designers to optimize products and manufacturing processes early in the design phase, reducing risks and costs.\n",
    "\n",
    "    - **What-If Analysis for Design Optimization:** Simulation-based what-if analysis allows designers to explore different variations in design, materials, or manufacturing processes. For example, engineers can simulate the impact of different materials or manufacturing methods on a product‚Äôs performance or cost. By testing these variations in a virtual environment, designers can identify the best options without having to build physical prototypes.\n",
    "\n",
    "    - **What-If Analysis for Manufacturing Optimization:** In manufacturing, what-if analysis can simulate the impact of changing production parameters, such as machine speeds or assembly line configurations, on overall efficiency, product quality, and cost. By leveraging simulation tools, manufacturers can optimize their processes, reducing waste, improving throughput, and ensuring higher quality outcomes.\n",
    "\n",
    "    - **Risk Mitigation:** What-if simulations help identify potential failure points in designs or manufacturing processes, allowing companies to take corrective actions before real-world consequences occur. This mitigates risks associated with new product introductions or process changes.\n",
    "\n",
    "- **Case Study: GE‚Äôs Digital Twin for Aircraft Engines:** **General Electric (GE)** has been a leader in implementing digital twin technology, particularly for aircraft engines. GE's digital twin for aircraft engines continuously collects real-time data from sensors embedded in the engines, which is then compared against the digital model of the engine. This allows GE to monitor the engine‚Äôs health throughout its operational lifecycle.\n",
    "  \n",
    "    - **Predictive Maintenance in Action:** By using a digital twin of the aircraft engine, GE can predict when maintenance will be needed, even before the engine shows signs of malfunction. This predictive capability allows airlines to schedule maintenance during downtime, reducing the risk of unexpected engine failures and costly flight delays.\n",
    "    \n",
    "    - **Optimization of Engine Performance:** The digital twin also allows GE to optimize the performance of the engines by analyzing real-time data against the digital model. This continuous feedback loop helps improve engine efficiency and fuel economy, and provides insights into how the engine performs under various operational conditions.\n",
    "\n",
    "    - **Improved Lifecycle Management:** The use of digital twins helps GE manage the entire lifecycle of its aircraft engines, from design and manufacturing to operations and maintenance. By utilizing simulation, real-time data, and predictive maintenance capabilities, GE is able to reduce operational costs and improve the reliability of its engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d313f",
   "metadata": {},
   "source": [
    "## 3.4 Example: Hands-on Excercise for Predictive Maintenance</font>\n",
    "\n",
    "#### Modelling Guide for Predictive Maintenance\n",
    "\n",
    "This example outlines the process of implementing a predictive maintenance model using a sample scenario where machine failures occur due to specific component malfunctions. The objective is to predict these failures. The example datasets illustrate key steps in predictive maintenance, including feature engineering, labeling, training, and evaluation.\n",
    "\n",
    "\n",
    "#### Example\n",
    "The example in this notebook considers a system with multiple components and sensors.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/machine.png\" alt=\"Alt text\" /></center>\n",
    "\n",
    "#### Outline\n",
    "\n",
    "- [Problem Description](#Problem-Description)\n",
    "- [Data Sources](#Data-Sources)\n",
    "   - [Telemetry](#Telemetry)\n",
    "   - [Errors](#Errors)\n",
    "   - [Maintenance](#Maintenance)\n",
    "   - [Machines](#Machines)\n",
    "   - [Failures](#Failures)\n",
    "- [Feature Engineering](#Feature-Engineering)\n",
    "  - [Lag Features from Telemetry](#Lag-Features-from-Telemetry)\n",
    "  - [Lag Features from Errors](#Lag-Features-from-Errors)\n",
    "  - [Days Since Last Replacement from Maintenance](#Days-Since-Last-Replacement-from-Maintenance)\n",
    "  - [Machine Features](#Machine-Features)\n",
    "- [Label Construction](#Label-Construction)\n",
    "- [Modelling](#Modelling)\n",
    "  - [Training, Validation and Testing](#Training,-Validation-and-Testing)\n",
    "  - [Evaluation](#Evaluation)\n",
    "- [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55a901",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.1 Problem Description</font>\n",
    "Businesses in asset-heavy industries, like manufacturing, face substantial costs due to production delays caused by mechanical problems. To mitigate the costly impact of downtime, these businesses seek to predict such issues in advance, allowing them to take proactive measures.\n",
    "\n",
    "In this example, the business problem involves predicting failures due to component malfunctions, answering the question, \"What is the probability that a machine will fail in the near future due to a specific component failure?\" This is framed as a multi-class classification problem, where a machine learning algorithm is employed to create a predictive model based on historical machine data.\n",
    "\n",
    "The following sections will guide you through the implementation steps of such a model, including feature engineering, label construction, training, and evaluation. In the next section, we begin by explaining the data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2351bb3",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.2 Data Sources</font>\n",
    "\n",
    "Common data sources for predictive maintenance problems are:\n",
    "\n",
    "- **Failure history**: The failure history of a machine or component within the machine.\n",
    "- **Maintenance history**: The repair history of a machine, e.g. error codes, previous maintenance activities or component replacements.\n",
    "- **Machine conditions and usage**: The operating conditions of a machine e.g. data collected from sensors.\n",
    "- **Machine features**: The features of a machine, e.g. engine size, make and model, location.\n",
    "- **Operator features**: The features of the operator, e.g. gender, past experience.\n",
    "\n",
    "The data for this example comes from 4 different sources: real-time telemetry data collected from machines, error messages, historical maintenance records that include failures, and machine information such as type and age.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc35216",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3931c2",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "telemetry = pd.read_csv('Module 3 Content/data/PdM_telemetry.csv')\n",
    "errors = pd.read_csv('Module 3 Content/data/PdM_errors.csv')\n",
    "maint = pd.read_csv('Module 3 Content/data/PdM_maint.csv')\n",
    "failures = pd.read_csv('Module 3 Content/data/PdM_failures.csv')\n",
    "machines = pd.read_csv('Module 3 Content/data/PdM_machines.csv')\n",
    "\n",
    "waiting_widget.value = \"<span style='color: green;'>‚úÖ Code Successful</span>\"\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52feb1",
   "metadata": {},
   "source": [
    "#### Telemetry\n",
    "\n",
    "The first data source is the telemetry time-series data which consists of voltage, rotation, pressure, and vibration measurements collected from 100 machines in real time averaged over every hour collected during the year 2015. Below, we display the first 5 records in the dataset. A summary of the whole dataset is also provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bdb24",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the telemetry data and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df317adf",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "telemetry['datetime'] = pd.to_datetime(telemetry['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "waiting_widget.value = \"<span style='color: green;'>‚úÖ Code Successful</span>\"\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"\\033[1m Total number of telemetry records: %d \\033[0m\" % len(telemetry.index))\n",
    "display(telemetry.head())\n",
    "telemetry.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d4550",
   "metadata": {},
   "source": [
    "As an example, below is a plot of voltage values for machine ID 1 for the first two months of 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52efad5",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the voltage values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2af10",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plot_df = telemetry.loc[(telemetry['machineID'] == 1) &\n",
    "                        (telemetry['datetime'] > pd.to_datetime('2015-01-01')) &\n",
    "                        (telemetry['datetime'] < pd.to_datetime('2015-02-01')), ['datetime', 'volt']]\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df['datetime'], plot_df['volt']);\n",
    "plt.ylabel('voltage')\n",
    "\n",
    "# make x-axis ticks legible\n",
    "adf = plt.gca().get_xaxis().get_major_formatter()\n",
    "adf.scaled[1.0] = '%m-%d'\n",
    "plt.xlabel('Date')\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6562f21",
   "metadata": {},
   "source": [
    "#### Errors\n",
    "\n",
    "The second major data source is the error logs. These are non-breaking errors thrown while the machine is still operational and do not constitute as failures. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb750f6",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show the error data and its count records per error ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c965717",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "errors['datetime'] = pd.to_datetime(errors['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "errors['errorID'] = errors['errorID'].astype('category')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "errors['errorID'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('Count');\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"\\033[1m Total number of error records: %d \\033[0m\" % len(errors.index))\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165fa90",
   "metadata": {},
   "source": [
    "#### Maintenance\n",
    "\n",
    "These are the scheduled and unscheduled maintenance records which correspond to both regular inspection of components as well as failures. A record is generated if a component is replaced during the scheduled inspection or replaced due to a breakdown. The records that are created due to breakdowns will be called failures which is explained in the later sections. Maintenance data has both 2014 and 2015 records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69b68a",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the maintenance data and its count records per component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d5641",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "maint['datetime'] = pd.to_datetime(maint['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "maint['comp'] = maint['comp'].astype('category')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "maint['comp'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('Count');\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"\\033[1m Total number of maintenance records: %d \\033[0m\" % len(maint.index))\n",
    "maint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c014574",
   "metadata": {},
   "source": [
    "#### Machines\n",
    "\n",
    "This data set includes some information about the machines: model type and age (years in service)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b746345",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display a sample of the machine data and its count over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03781081",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "machines['model'] = machines['model'].astype('category')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "_, bins, _ = plt.hist([machines.loc[machines['model'] == 'model1', 'age'],\n",
    "                       machines.loc[machines['model'] == 'model2', 'age'],\n",
    "                       machines.loc[machines['model'] == 'model3', 'age'],\n",
    "                       machines.loc[machines['model'] == 'model4', 'age']],\n",
    "                       20, stacked=True, label=['model1', 'model2', 'model3', 'model4'])\n",
    "plt.xlabel('Age (yrs)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend();\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"\\033[1m Total number of machines: %d \\033[0m\" % len(machines.index))\n",
    "machines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077db47",
   "metadata": {},
   "source": [
    "#### Failures\n",
    "\n",
    "These are the records of component replacements due to failures. Each record has a date and time, machine ID, and failed component type.\n",
    "\n",
    "Below is the histogram of the failures due to each component. We see that component 2 causes the most failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09990dd2",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display a sample of the failure data and its count per component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113093f",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "failures['datetime'] = pd.to_datetime(failures['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "failures['failure'] = failures['failure'].astype('category')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "failures['failure'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('Count');\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"\\033[1m Total number of failures: %d \\033[0m\" % len(failures.index))\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b003b2",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.3 Feature Engineering</font>\n",
    "\n",
    "The first step in predictive maintenance applications is feature engineering which requires bringing the different data sources together to create features that best describe a machines's health condition at a given point in time. In the next sections, several feature engineering methods are used to create features based on the properties of each data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbe735",
   "metadata": {},
   "source": [
    "#### Lag Features from Telemetry\n",
    "\n",
    "Telemetry data almost always comes with time-stamps which makes it suitable for calculating lagging features. A common method is to pick a window size for the lag features to be created and compute rolling aggregate measures such as mean, standard deviation, minimum, maximum, etc. to represent the short term history of the telemetry over the lag window. In the following, rolling mean and standard deviation of the telemetry data over the last 3 hour lag window is calculated for every 3 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48ceca",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show the 3 hour lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd7ac4",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Loading Data, Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# Calculate mean values for telemetry features\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right').mean().unstack())\n",
    "telemetry_mean_3h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_3h.columns = [i + 'mean_3h' for i in fields]\n",
    "telemetry_mean_3h.reset_index(inplace=True)\n",
    "\n",
    "# repeat for standard deviation\n",
    "temp = []\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right').std().unstack())\n",
    "telemetry_sd_3h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_3h.columns = [i + 'sd_3h' for i in fields]\n",
    "telemetry_sd_3h.reset_index(inplace=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "telemetry_mean_3h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da3d3f",
   "metadata": {},
   "source": [
    "For capturing a longer term effect, 24 hour lag features are also calculated as below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1555d",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show the 24 hour lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7e158",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Loading Data, Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    rolling_mean = pd.pivot_table(telemetry,\n",
    "                                  index='datetime',\n",
    "                                  columns='machineID',\n",
    "                                  values=col).rolling(window=24).mean()    \n",
    "    resampled = rolling_mean.resample('3H', closed='left', label='right').first().unstack()\n",
    "    temp.append(resampled)\n",
    "    \n",
    "telemetry_mean_24h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_24h.columns = [i + 'mean_24h' for i in fields]\n",
    "telemetry_mean_24h.reset_index(inplace=True)\n",
    "telemetry_mean_24h = telemetry_mean_24h.loc[-telemetry_mean_24h['voltmean_24h'].isnull()]\n",
    "\n",
    "# repeat for standard deviation\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    rolling_std = pd.pivot_table(telemetry,\n",
    "                                  index='datetime',\n",
    "                                  columns='machineID',\n",
    "                                  values=col).rolling(window=24).std()\n",
    "    resampled = rolling_std.resample('3H', closed='left', label='right').first().unstack()\n",
    "    temp.append(resampled)\n",
    "    \n",
    "telemetry_sd_24h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_24h.columns = [i + 'sd_24h' for i in fields]\n",
    "telemetry_sd_24h.reset_index(inplace=True)\n",
    "telemetry_sd_24h = telemetry_sd_24h.loc[-telemetry_sd_24h['voltsd_24h'].isnull()]\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Notice that a 24h rolling average is not available at the earliest timepoints\n",
    "telemetry_mean_24h.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8091630",
   "metadata": {},
   "source": [
    "Next, the columns of the feature datasets created earlier are merged to create the final feature set from telemetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d821f",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the final feature set from telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1358677",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "# merge columns of feature sets created earlier\n",
    "telemetry_feat = pd.concat([telemetry_mean_3h,\n",
    "                            telemetry_sd_3h.iloc[:, 2:6],\n",
    "                            telemetry_mean_24h.iloc[:, 2:6],\n",
    "                            telemetry_sd_24h.iloc[:, 2:6]], axis=1).dropna()\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print('\\033[1mThis is a sample of the data.\\033[0m\\n')\n",
    "display(telemetry_feat.head())\n",
    "print('\\n\\033[1mThis is the summary of the entire data\\033[0m\\n')\n",
    "telemetry_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36687e6c",
   "metadata": {},
   "source": [
    "This is a sample of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc35ae",
   "metadata": {},
   "source": [
    "#### Lag Features from Errors\n",
    "\n",
    "Like telemetry data, errors come with timestamps. An important difference is that the error IDs are categorical values and should not be averaged over time intervals like the telemetry measurements. Instead, we count the number of errors of each type in a lagging window. We begin by reformatting the error data to have one entry per machine per time at which at least one error occurred:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bb197",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the updated error data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5130b",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create a column for each error type\n",
    "error_count = pd.get_dummies(errors.set_index('datetime')).reset_index()\n",
    "error_count.columns = ['datetime', 'machineID', 'error1', 'error2', 'error3', 'error4', 'error5']\n",
    "\n",
    "# combine errors for a given machine in a given hour\n",
    "error_count = error_count.groupby(['machineID', 'datetime']).sum().reset_index()\n",
    "error_count.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103c9ba",
   "metadata": {},
   "source": [
    "Now we add blank entries for all other hourly timepoints (since no errors occurred at those times):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff6b93",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the summary of the updated error data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c891b8a",
   "metadata": {},
   "source": [
    "error_count = telemetry[['datetime', 'machineID']].merge(error_count, on=['machineID', 'datetime'], how='left').fillna(0.0)\n",
    "error_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad0370",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the summary of the updated error data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90710d7",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "error_count = telemetry[['datetime', 'machineID']].merge(error_count, on=['machineID', 'datetime'], how='left').fillna(0.0)\n",
    "clear_output(wait=True)\n",
    "error_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7ed09",
   "metadata": {},
   "source": [
    "#### Days Since Last Replacement from Maintenance\n",
    "\n",
    "A crucial data set in this example is the maintenance records which contain the information of component replacement records. Possible features from this data set can be, for example, the number of replacements of each component in the last 3 months to incorporate the frequency of replacements. However, more relevent information would be to calculate how long it has been since a component is last replaced as that would be expected to correlate better with component failures since the longer a component is used, the more degradation should be expected. \n",
    "\n",
    "As a side note, creating lagging features from maintenance data is not as straightforward as for telemetry and errors, so the features from this data are generated in a more custom way. This type of ad-hoc feature engineering is very common in predictive maintenance since domain knowledge plays a big role in understanding the predictors of a problem. In the following, the days since last component replacement are calculated for each component type as features from the maintenance data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d911db",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show a sample of the maintenance data and its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87006dfe",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Loading Data, Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "\n",
    "# create a column for each error type\n",
    "comp_rep = pd.get_dummies(maint.set_index('datetime')).reset_index()\n",
    "comp_rep.columns = ['datetime', 'machineID', 'comp1', 'comp2', 'comp3', 'comp4']\n",
    "\n",
    "# combine repairs for a given machine in a given hour\n",
    "comp_rep = comp_rep.groupby(['machineID', 'datetime']).sum().reset_index()\n",
    "\n",
    "# add timepoints where no components were replaced\n",
    "comp_rep = telemetry[['datetime', 'machineID']].merge(comp_rep,\n",
    "                                                      on=['datetime', 'machineID'],\n",
    "                                                      how='outer').fillna(0).sort_values(by=['machineID', 'datetime'])\n",
    "\n",
    "components = ['comp1', 'comp2', 'comp3', 'comp4']\n",
    "for comp in components:\n",
    "    # convert indicator to most recent date of component change\n",
    "    comp_rep.loc[comp_rep[comp] < 1, comp] = None\n",
    "    comp_rep.loc[-comp_rep[comp].isnull(), comp] = comp_rep.loc[-comp_rep[comp].isnull(), 'datetime']\n",
    "    \n",
    "    # forward-fill the most-recent date of component change\n",
    "    comp_rep[comp] = comp_rep[comp].fillna(method='ffill')\n",
    "\n",
    "# remove dates in 2014 (may have NaN or future component change dates)    \n",
    "comp_rep = comp_rep.loc[comp_rep['datetime'] > pd.to_datetime('2015-01-01')]\n",
    "\n",
    "# replace dates of most recent component change with days since most recent component change\n",
    "for comp in components:\n",
    "    comp_rep[comp] = (comp_rep['datetime'] - comp_rep[comp]) / np.timedelta64(1, 'D')\n",
    "    \n",
    "clear_output(wait=True)\n",
    "\n",
    "print('\\033[1mThis is sample of the data.\\033[0m\\n')\n",
    "display(comp_rep.head())\n",
    "\n",
    "print('\\n\\033[1mThis is the summary of the data.\\033[0m\\n')\n",
    "comp_rep.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c86d99",
   "metadata": {},
   "source": [
    "#### Machine Features\n",
    "\n",
    "The machine features can be used without further modification. These include descriptive information about the type of each machine and its age (number of years in service). If the age information had been recorded as a \"first use date\" for each machine, a transformation would have been necessary to turn those into a numeric values indicating the years in service.\n",
    "\n",
    "Lastly, we merge all the feature data sets we created earlier to get the final feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9b346",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show a sample of the final feature data and its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d363fc4",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "final_feat = telemetry_feat.merge(error_count, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(comp_rep, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(machines, on=['machineID'], how='left')\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(final_feat)\n",
    "#display(final_feat.head())\n",
    "final_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4531683",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.4 Label Construction</font>\n",
    "\n",
    "When using multi-class classification for predicting failure due to a problem, labelling is done by taking a time window prior to the failure of an asset and labelling the feature records that fall into that window as \"about to fail due to a problem\" while labelling all other records as \"normal.\" This time window should be picked according to the business case: in some situations it may be enough to predict failures hours in advance, while in others days or weeks may be needed to allow e.g. for arrival of replacement parts.\n",
    "\n",
    "The prediction problem for this example scenerio is to estimate the probability that a machine will fail in the near future due to a failure of a certain component. More specifically, the goal is to compute the probability that a machine will fail in the next 24 hours due to a certain component failure (component 1, 2, 3, or 4). Below, a categorical `failure` feature is created to serve as the label. All records within a 24 hour window before a failure of component 1 have `failure=comp1`, and so on for components 2, 3, and 4; all records not within 24 hours of a component failure have `failure=none`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cdde48",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show the feature data and its \"failure\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde6131",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: green;'>‚úÖ Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "labeled_features = final_feat.merge(failures, on=['datetime', 'machineID'], how='left')\n",
    "labeled_features = labeled_features.fillna(method='bfill', limit=7) # fill backward up to 24h\n",
    "\n",
    "for col in labeled_features.select_dtypes(include='category').columns:\n",
    "    labeled_features[col] = labeled_features[col].astype(str)\n",
    "\n",
    "labeled_features = labeled_features.replace('nan', 'none')\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "labeled_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699de38",
   "metadata": {},
   "source": [
    "Below is an example of records that are labeled as `failure=comp4` in the failure column. Notice that the first 8 records all occur in the 24-hour window before the first recorded failure of component 4. The next 8 records are within the 24 hour window before another failure of component 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260ac62",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show an example of \"comp4\" failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29f424",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "labeled_features.loc[labeled_features['failure'] == 'comp4'][:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c941a",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.5 Modelling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877027a5",
   "metadata": {},
   "source": [
    "#### Training, Validation and Testing\n",
    "\n",
    "When working with time-stamped data as in this example, record partitioning into training, validation, and test sets should be performed carefully to prevent overestimating the performance of the models. In predictive maintenance, the features are usually generated using lagging aggregates: records in the same time window will likely have identical labels and similar feature values. These correlations can give a model an \"unfair advantage\" when predicting on a test set record that shares its time window with a training set record. We therefore partition records into training, validation, and test sets in large chunks, to minimize the number of time intervals shared between them.\n",
    "\n",
    "Predictive models have no advance knowledge of future chronological trends: in practice, such trends are likely to exist and to adversely impact the model's performance. To obtain an accurate assessment of a predictive model's performance, we recommend training on older records and validating/testing using newer records.\n",
    "\n",
    "For both of these reasons, a time-dependent record splitting strategy is an excellent choice for predictive maintenace models. The split is effected by choosing a point in time based on the desired size of the training and test sets: all records before the timepoint are used for training the model, and all remaining records are used for testing. (If desired, the timeline could be further divided to create validation sets for parameter selection.) To prevent any records in the training set from sharing time windows with the records in the test set, we remove any records at the boundary -- in this case, by ignoring 24 hours' worth of data prior to the timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075217c6",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to train the model and predict the test results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152128b",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# make test and training splits\n",
    "threshold_dates = [[pd.to_datetime('2015-07-31 01:00:00'), pd.to_datetime('2015-08-01 01:00:00')],\n",
    "                   [pd.to_datetime('2015-08-31 01:00:00'), pd.to_datetime('2015-09-01 01:00:00')],\n",
    "                   [pd.to_datetime('2015-09-30 01:00:00'), pd.to_datetime('2015-10-01 01:00:00')]]\n",
    "\n",
    "test_results = []\n",
    "models = []\n",
    "for last_train_date, first_test_date in threshold_dates:\n",
    "    # split out training and test data\n",
    "    train_y = labeled_features.loc[labeled_features['datetime'] < last_train_date, 'failure']\n",
    "    train_X = pd.get_dummies(labeled_features.loc[labeled_features['datetime'] < last_train_date].drop(columns=['datetime',\n",
    "                                                                                                        'machineID',\n",
    "                                                                                                        'failure']))\n",
    "    test_X = pd.get_dummies(labeled_features.loc[labeled_features['datetime'] > first_test_date].drop(columns=['datetime',\n",
    "                                                                                                       'machineID',\n",
    "                                                                                                       'failure']))\n",
    "    # train and predict using the model, storing results for later\n",
    "    my_model = HistGradientBoostingClassifier(max_depth = 9, verbose=2, random_state=42)\n",
    "    my_model.fit(train_X, train_y)\n",
    "    test_result = pd.DataFrame(labeled_features.loc[labeled_features['datetime'] > first_test_date])\n",
    "    test_result['predicted_failure'] = my_model.predict(test_X)\n",
    "    test_results.append(test_result)\n",
    "    models.append(my_model)\n",
    "    \n",
    "waiting_widget.value = \"<span style='color: green;'>‚úÖ Code Successful</span>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983afe8",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>3.4.6 Evaluation</font>\n",
    "\n",
    "In predictive maintenance, machine failures are usually rare occurrences in the lifetime of the assets compared to normal operations. This causes an imbalance in the label distribution, which usually causes poor performance as algorithms tend to classify majority class examples better at the expense of minority class examples, as the total misclassification error is much improved when the majority class is labeled correctly.  This causes low recall rates, although accuracy can be high, and becomes a larger problem when the cost of false alarms to the business is very high. To help with this problem, sampling techniques such as oversampling of the minority examples are usually used along with more sophisticated techniques that are not covered in this notebook.\n",
    "\n",
    "#### Data Imbalance\n",
    "\n",
    "Visualize the categories distribution. We clearly see that the \"none\" class is dominant and there is a data imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4b9cb",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the distribution of the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6edeb0",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "labeled_features['failure'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Component failing')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecb3d9",
   "metadata": {},
   "source": [
    "#### Baseline Classification Metrics\n",
    "\n",
    "Also, due to the class imbalance problem, it is important to look at evaluation metrics other than accuracy alone and compare those metrics to the baseline metrics, which are computed when random chance is used to make predictions rather than a machine learning model.  The comparison will better highlight the value and benefits of using a machine learning model.\n",
    "\n",
    "In the following, we use an evaluation function that computes many important evaluation metrics and baseline metrics for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9dfc6",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to display the confusion matrices the three different splits and the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af281235",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "waiting_widget = widgets.HTML(value=\"<span style='color: orange;'>üüß Code Running Please Wait ...</span>\")\n",
    "display(waiting_widget)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "import itertools\n",
    "\n",
    "def Evaluate(predicted, actual, labels):\n",
    "    output_labels = []\n",
    "    output = []\n",
    "    \n",
    "    # Calculate and display confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted, labels=labels)\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Annotating the confusion matrix\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #print('Confusion matrix\\n- x-axis is true labels (none, comp1, etc.)\\n- y-axis is predicted labels')\n",
    "    #print(cm)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    accuracy = np.array([float(np.trace(cm)) / np.sum(cm)] * len(labels))\n",
    "    precision = precision_score(actual, predicted, average=None, labels=labels)\n",
    "    recall = recall_score(actual, predicted, average=None, labels=labels)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    output.extend([accuracy.tolist(), precision.tolist(), recall.tolist(), f1.tolist()])\n",
    "    output_labels.extend(['accuracy', 'precision', 'recall', 'F1'])\n",
    "    \n",
    "    # Calculate the macro versions of these metrics\n",
    "    output.extend([[np.mean(precision)] * len(labels),\n",
    "                   [np.mean(recall)] * len(labels),\n",
    "                   [np.mean(f1)] * len(labels)])\n",
    "    output_labels.extend(['macro precision', 'macro recall', 'macro F1'])\n",
    "    \n",
    "    # Find the one-vs.-all confusion matrix\n",
    "    cm_row_sums = cm.sum(axis = 1)\n",
    "    cm_col_sums = cm.sum(axis = 0)\n",
    "    s = np.zeros((2, 2))\n",
    "    for i in range(len(labels)):\n",
    "        v = np.array([[cm[i, i],\n",
    "                       cm_row_sums[i] - cm[i, i]],\n",
    "                      [cm_col_sums[i] - cm[i, i],\n",
    "                       np.sum(cm) + cm[i, i] - (cm_row_sums[i] + cm_col_sums[i])]])\n",
    "        s += v\n",
    "    s_row_sums = s.sum(axis = 1)\n",
    "    \n",
    "    # Add average accuracy and micro-averaged  precision/recall/F1\n",
    "    avg_accuracy = [np.trace(s) / np.sum(s)] * len(labels)\n",
    "    micro_prf = [float(s[0,0]) / s_row_sums[0]] * len(labels)\n",
    "    output.extend([avg_accuracy, micro_prf])\n",
    "    output_labels.extend(['average accuracy',\n",
    "                          'micro-averaged precision/recall/F1'])\n",
    "    \n",
    "    # Compute metrics for the majority classifier\n",
    "    mc_index = np.where(cm_row_sums == np.max(cm_row_sums))[0][0]\n",
    "    cm_row_dist = cm_row_sums / float(np.sum(cm))\n",
    "    mc_accuracy = 0 * cm_row_dist; mc_accuracy[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_recall = 0 * cm_row_dist; mc_recall[mc_index] = 1\n",
    "    mc_precision = 0 * cm_row_dist\n",
    "    mc_precision[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_F1 = 0 * cm_row_dist;\n",
    "    mc_F1[mc_index] = 2 * mc_precision[mc_index] / (mc_precision[mc_index] + 1)\n",
    "    output.extend([mc_accuracy.tolist(), mc_recall.tolist(),\n",
    "                   mc_precision.tolist(), mc_F1.tolist()])\n",
    "    output_labels.extend(['majority class accuracy', 'majority class recall',\n",
    "                          'majority class precision', 'majority class F1'])\n",
    "        \n",
    "    # Random accuracy and kappa\n",
    "    cm_col_dist = cm_col_sums / float(np.sum(cm))\n",
    "    exp_accuracy = np.array([np.sum(cm_row_dist * cm_col_dist)] * len(labels))\n",
    "    kappa = (accuracy - exp_accuracy) / (1 - exp_accuracy)\n",
    "    output.extend([exp_accuracy.tolist(), kappa.tolist()])\n",
    "    output_labels.extend(['expected accuracy', 'kappa'])\n",
    "    \n",
    "\n",
    "    # Random guess\n",
    "    rg_accuracy = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_precision = cm_row_dist\n",
    "    rg_recall = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_F1 = 2 * cm_row_dist / (len(labels) * cm_row_dist + 1)\n",
    "    output.extend([rg_accuracy.tolist(), rg_precision.tolist(),\n",
    "                   rg_recall.tolist(), rg_F1.tolist()])\n",
    "    output_labels.extend(['random guess accuracy', 'random guess precision',\n",
    "                          'random guess recall', 'random guess F1'])\n",
    "    \n",
    "    # Random weighted guess\n",
    "    rwg_accuracy = np.ones(len(labels)) * sum(cm_row_dist**2)\n",
    "    rwg_precision = cm_row_dist\n",
    "    rwg_recall = cm_row_dist\n",
    "    rwg_F1 = cm_row_dist\n",
    "    output.extend([rwg_accuracy.tolist(), rwg_precision.tolist(),\n",
    "                   rwg_recall.tolist(), rwg_F1.tolist()])\n",
    "    output_labels.extend(['random weighted guess accuracy',\n",
    "                          'random weighted guess precision',\n",
    "                          'random weighted guess recall',\n",
    "                          'random weighted guess F1'])\n",
    "\n",
    "    output_df = pd.DataFrame(output, columns=labels)\n",
    "    output_df.index = output_labels\n",
    "                  \n",
    "    return output_df\n",
    "\n",
    "evaluation_results = []\n",
    "for i, test_result in enumerate(test_results):\n",
    "    print('\\n\\033[1mSplit %d:\\033[0m' % (i+1))\n",
    "    evaluation_result = Evaluate(actual = test_result['failure'],\n",
    "                                 predicted = test_result['predicted_failure'],\n",
    "                                 labels = ['none', 'comp1', 'comp2', 'comp3', 'comp4'])\n",
    "    evaluation_results.append(evaluation_result)\n",
    "evaluation_results[0]  # show full results for first split only\n",
    "waiting_widget.value = \"<span style='color: green;'>‚úÖ Code Successful</span>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a59c3",
   "metadata": {},
   "source": [
    "#### Evaluation Highlights\n",
    "In predictive maintenance, we are often most concerned with how many of the actual failures were predicted by the model, i.e. the model's recall. (Recall becomes more important as the consequences of *false negatives* -- true failures that the model did not predict -- exceed the consequences of *false positives*, viz. false prediction of impending failure.) Below, we compare the recall rates for each failure type for the three models. The recall rates for all components as well as no failure are all above 90% meaning the model was able to capture above 90% of the failures correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe6d77",
   "metadata": {},
   "source": [
    "#### Press ‚ñ∂ to show the recall values per split per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f1793",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "recall_df = pd.DataFrame([evaluation_results[0].loc['recall'].values,\n",
    "                          evaluation_results[1].loc['recall'].values,\n",
    "                          evaluation_results[2].loc['recall'].values],\n",
    "                         columns = ['none', 'comp1', 'comp2', 'comp3', 'comp4'],\n",
    "                         index = ['recall for first split',\n",
    "                                  'recall for second split',\n",
    "                                  'recall for third split'])\n",
    "recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8e5ca",
   "metadata": {},
   "source": [
    "## 3.5 Example 2: Conceptual Concept for Predictive Maintenance of Aircraft Gas Turbine Engines\n",
    "\n",
    "### <font color = '#646464'>3.5.1 Problem Formulation</font>\n",
    "In modern aviation, ensuring the reliability and safety of aircraft gas turbine engines is paramount. Unplanned engine failures can lead to severe operational disruptions, increased maintenance costs, and, most critically, safety risks. Traditional maintenance strategies, such as reactive (run-to-failure) or scheduled preventative maintenance, often result in either unnecessary early component replacements or failures occurring between scheduled inspections. To mitigate these issues, a data-driven predictive maintenance framework is essential ‚Äî leveraging real-time sensory data to anticipate failures and optimize maintenance schedules.\n",
    "\n",
    "### <font color = '#646464'>3.5.2 Goal</font>\n",
    "The goal of this predictive maintenance approach is to shift from time-based or usage-based servicing to a more intelligent, condition-based maintenance (CBM) paradigm. This involves continuously monitoring engine performance through a network of onboard sensors that capture critical parameters such as temperature, pressure, vibration, fuel flow, and rotational speeds. By analyzing historical trends and current sensor readings, degradation patterns can be identified, allowing for early fault detection, Remaining Useful Life (RUL) estimation, and dynamic maintenance planning.\n",
    "\n",
    "#### Inputs\n",
    "Multivariate time-series sensor data from the aircraft engine (e.g., temperature, pressure, vibration), as shown in the Table below.\n",
    "\n",
    "#### Outputs\n",
    "Predictive insights, including component health status, estimated time to failure, and recommended maintenance action times.\n",
    "\n",
    "#### Approach\n",
    "A statistical framework that processes multi-sensory data collected up to the current time and predicts the system's degradation profile and remaining useful life.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Table1.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "**Goal:** Construct a degradation score and identify a threshold at which condition-based maintenance would be recommended. \n",
    "\n",
    "**Approach:** \n",
    "\n",
    "1. Construct a fused health index based on the sensory data that can separate the health states of an engine. The figure below shows an ideal health index that can clearly separate between failure state (0), state just before failure (1), and so on. The figure shows the health index for multiple engines, and the variations between the engines at a given state are negligible compared to the gap between the two states. In other words, the 95% CI of the distribution in black is much smaller than the solid lines.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Health_state.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "The optimization function used to find the best possible health index from historical engines that ran until failure in a controlled environment is shown below:\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Optimization_function.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "Here, deep learning calculates the health index as a fused signal of the multiple sensors.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/model.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "The optimization function aims to separate any two consecutive states from one side, thus resulting in a monotonic health index where the statistical distance between consecutive states is maximized. The optimization objective function is inspired by a series of hypothesis testing shown below.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/hypothesis.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "The figure below shows an example outcome from a practical scenario in real time. The fused signal is less noisy and easier to forecast.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Fused_signal.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "\n",
    "2. Find the statistical distribution of the health index values at all health states, including State 0 (failure), State 1, ..., and normal operating state. The figure below shows the distributions to be estimated in green boxes. Each state will have its own distribution.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Distributions.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "3. In real time, the health state can be estimated by finding the maximum likelihood state that fits the observed multiple sensor data. The governing equations to find the maximum-likelihood estimate (MLE) for the state are:\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/MLE_1.JPG\" alt=\"Alt text\" /></center>\n",
    "Using Bayesian statistics, we know that the likelihood that a calculated health-index measurement belongs to the distribution of health index values from state p is proportion to the probability that the health state is \"p\" given the calculated health index. Here, h_p represents the distribution for state p, and h_i,t represents the real-time calculated health-index value for engine i at time t.\n",
    "\n",
    "Then, the MLE health-state is the answer for the following optimization problem:\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/MLE2.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "Without diving into the detailed derivations, this simplifies to\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/MLE3.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "Here, we assume that the calculated health index is not a single static number but a distribution that is more robust to noisy sensory data. This is why the health index is smoother than the individual sensor data, as was shown in one of the previous figures. Specifically, the distribution for the calculated health-index follows:\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/h_i_distr.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "4. Construct a normalized degradation score between 0 and 1 that will be later useful to identify a trigger for recommending predictive maintenance. One potential estimation for the DS is:\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/DS_eq.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "Here, N is the number of health states.\n",
    "\n",
    "The figure shows an example engine around 100 cycles before failing one requirement for its intended function. To achieve this figure, the health index is forecasted using a machine learning algorithm with every forecast, we find the MLE state until we reach the failure MLE state.\n",
    "\n",
    "5. Forecast the health index and the degradation score. Specifically, the health index is forecasted using a machine learning algorithm with every forecast, we find the MLE state and then find the DS. Once the MLE state is the failure state, then the engine is assumed to have reached failure at the forecasted time point.\n",
    "\n",
    "The figure below shows an example for forecasting the DS and finding the failure cycle. The figure shows that the predicted failure cycle is 268 but the true failure cycle was 251. In other words, the DS at true failure is 0.88 and predicted DS at failure is always 1 by defintion.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Result.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "6. Find a threshold, and when the DS surpasses it, condition-based predictive maintenance is requested. This threshold is estimated based on historical engines and the predictive performance of the DS. The figure below shows all the predicted DS at true failure and it is clear that a threshold of 0.7 is sufficient to request maintenance. There is only one anomolous point below 0.7.\n",
    "\n",
    "<center><img src=\"Module 3 Content/img/Predictive_maintenance.JPG\" alt=\"Alt text\" /></center>\n",
    "\n",
    "**Conclusion**: This concludes the predictive maintenance example, where a digital thread that orchestrates the accessibility of the sensor data for different components of the engine can be utilized for effective strategies for predictive maintenance and helps avoid unexpected failures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23500f4",
   "metadata": {},
   "source": [
    "## 3.6 Cybersecurity & Data Integrity in MBE\n",
    "\n",
    "### <font color = '#646464'>3.6.1 Securing the MBE Ecosystem</font>\n",
    "**Goal:** To ensure that the Model-Based Enterprise (MBE) ecosystem is secure from external threats, unauthorized access, and tampering, while maintaining the integrity of the design, manufacturing, and sustainment processes.\n",
    "\n",
    "- **Implementing Zero Trust Architecture (ZTA) in Digital Engineering Workflows:** **Zero Trust Architecture (ZTA)** is an advanced security framework that assumes no entity, inside or outside the organization, can be trusted by default. ZTA requires verification and authorization for every user, device, and application attempting to access resources, ensuring that security is enforced at every level.\n",
    "  \n",
    "    - **Access Control Based on Identity and Context:** In the context of digital engineering workflows, Zero Trust can be implemented by enforcing strict access controls for users, devices, and systems at all stages of the product lifecycle. This includes designing, manufacturing, and sustaining digital assets such as CAD models, simulation data, and digital twins.\n",
    "    \n",
    "    - **Continuous Monitoring and Authentication:**  \n",
    "      ZTA continuously monitors all activities across the MBE ecosystem, ensuring that any unusual or suspicious behavior is detected and addressed in real-time. This might include ensuring that the user requesting access has valid credentials, that the devices are properly authenticated, and that the request complies with the established security policies.\n",
    "    \n",
    "    - **Granular Access to Data & Systems:** In a Zero Trust environment, each step of the workflow, from design to manufacturing to maintenance, would have strict, role-based controls. These controls could restrict access to sensitive data such as intellectual property (IP), proprietary algorithms, and sensitive customer information, ensuring that only authorized personnel can interact with specific parts of the system.\n",
    "\n",
    "- **Blockchain for Tamper-Proof Design & Manufacturing Records:** Blockchain technology can provide a secure, transparent, and immutable record of all activities within the MBE ecosystem. Each transaction (or change) in the product lifecycle is recorded in a decentralized ledger, making it impossible to alter or delete past records without detection.\n",
    "  \n",
    "    - **Tamper-Proof Records:** Blockchain provides tamper-proof records by creating a chain of blocks that securely store design, manufacturing, and testing data. As each step is completed in the MBE process (e.g., a new design iteration, a change in manufacturing specifications, or a product test), a cryptographic hash is generated and recorded in the blockchain. This ensures that every change is permanent and cannot be retroactively altered, protecting the integrity of the data.\n",
    "    \n",
    "    - **Traceability of Design Changes:** Blockchain‚Äôs transparency makes it easy to track and verify design changes throughout the product lifecycle. In industries like aerospace, automotive, or defense, where safety and reliability are paramount, this feature ensures that every change is traceable, providing an audit trail that can be used for verification and compliance purposes.\n",
    "    \n",
    "    - **Smart Contracts for Manufacturing and Supply Chain:** **Smart contracts** (self-executing contracts with the terms of the agreement directly written into code) can be used to automate and enforce agreements between parties in the manufacturing and supply chain processes. These contracts ensure that only authorized changes or updates can occur, further enhancing the security and efficiency of the ecosystem.\n",
    "\n",
    "---\n",
    "\n",
    "### <font color = '#646464'>4.2 Digital Rights Management (DRM) & Access Control</font>\n",
    "**Goal:** To safeguard intellectual property (IP) and sensitive data in a collaborative MBE environment, ensuring that only authorized individuals can access or modify designs and engineering information.\n",
    "\n",
    "- **Ensuring Intellectual Property Protection in Collaborative Environments:** The collaborative nature of MBE, where multiple stakeholders across different organizations or departments interact with digital models and data, makes intellectual property protection a critical issue. MBE involves sharing sensitive designs and data between design teams, manufacturers, suppliers, and maintenance providers, all of whom need access to specific parts of the product lifecycle. \n",
    "   \n",
    "    - **Watermarking and Encryption:** **Digital watermarking** can be applied to CAD models, simulation data, and other digital assets to uniquely identify their origin and prevent unauthorized copying or distribution. Additionally, **encryption** methods can be used to secure sensitive design data, making it unreadable to unauthorized parties.\n",
    "    \n",
    "    - **Control over Distribution and Use of IP:** To prevent unauthorized sharing or use of sensitive designs, DRM tools can enforce restrictions on the copying, printing, or distributing of intellectual property. For instance, encrypted CAD files might require special software or keys to open and work with, ensuring that only authorized personnel can interact with the design.\n",
    "    \n",
    "    - **Tracking and Auditing IP Usage:** DRM tools also allow for the monitoring and tracking of how intellectual property is accessed and used. This means that every access event can be logged and reviewed, providing a clear audit trail of who viewed, modified, or shared the data and under what circumstances.\n",
    "\n",
    "- **Role-Based Access Control for PLM & MBE Tools:** **Role-Based Access Control (RBAC)** is a security paradigm used to restrict access to resources based on the roles of individual users within an organization. By using RBAC, MBE tools and PLM systems can be tailored to ensure that users only have access to the data and functionality necessary for their roles, improving security and protecting sensitive information.\n",
    "  \n",
    "    - **Granular Role Assignments:** In MBE, different teams (e.g., designers, engineers, manufacturers, suppliers) have varying levels of access to data and tools. RBAC ensures that each user has access to the appropriate resources based on their role. For instance, a manufacturing engineer may have access to manufacturing specifications but not to sensitive design data, while a design engineer would have access to the CAD model but not to production scheduling.\n",
    "    \n",
    "    - **Separation of Duties:** RBAC also helps enforce the principle of separation of duties, ensuring that no individual has control over the entire product lifecycle or the ability to make changes to critical data without oversight. This can prevent fraud or errors and ensure that critical tasks (e.g., approval processes) are carried out by the appropriate personnel.\n",
    "    \n",
    "    - **Access Auditing and Monitoring:** For added security, RBAC systems allow for logging and auditing of all access events. This enables administrators to monitor who is accessing sensitive data or systems and when, and to ensure that users are adhering to established policies. If an anomaly is detected, immediate actions can be taken, such as revoking access or conducting an investigation.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.7 Large Scale Real-World Applications\n",
    "\n",
    "### <font color = '#646464'>3.7.1 MBE Implementation in Aerospace & Defense</font>\n",
    "**Goal:** To explore how MBE and its associated methodologies are applied in highly complex industries like aerospace and defense, where precision, collaboration, and innovation are critical.\n",
    "\n",
    "- **Lockheed Martin‚Äôs MBE Approach for F-35 Production:** Lockheed Martin has revolutionized the way military aircraft like the F-35 Lightning II are designed, built, and sustained by implementing Model-Based Engineering (MBE). In this case, MBE plays a critical role throughout the entire lifecycle of the aircraft, from design to manufacturing and sustainment.\n",
    "  \n",
    "    - **End-to-End Integration:** Lockheed Martin integrated MBE across all stages of the aircraft's lifecycle. From initial conceptual design, detailed modeling, and simulation, to production and sustainment, digital models are used as the **single source of truth**. These models ensure that all stakeholders, including designers, engineers, suppliers, and maintenance teams, have access to accurate and up-to-date information.\n",
    "    \n",
    "    - **Digital Thread:** The Digital Thread concept ties together all aspects of the aircraft‚Äôs lifecycle, enabling seamless communication and information exchange across different systems. This ensures that changes made during any phase of the lifecycle are reflected across the entire ecosystem, leading to better collaboration, fewer errors, and increased operational efficiency.\n",
    "    \n",
    "    - **Reduced Development Time and Costs:** By utilizing MBE, Lockheed Martin has been able to reduce development time and costs for the F-35 program. Digital models have been used to simulate manufacturing processes, perform virtual testing, and predict potential issues, which has led to a more streamlined and efficient production process.\n",
    "\n",
    "<center><img src=\"https://defense.info/wp-content/uploads/2018/11/Screen-Shot-2018-11-07-at-4.54.18-AM-1024x569.png\" alt=\"Alt text\" /></center>\n",
    "\n",
    "---\n",
    "\n",
    "## 3.8 Automotive & Manufacturing Applications\n",
    "**Goal:** To showcase how MBE is being adopted in automotive and manufacturing industries to optimize design, improve production efficiency, and enable real-time decision-making.\n",
    "\n",
    "- **MBE-Driven Smart Manufacturing at BMW & Tesla:** Both BMW and Tesla are leaders in the adoption of Smart Manufacturing driven by MBE principles, enabling faster innovation, more efficient production, and enhanced product quality. In these companies, MBE technologies like Digital Twins, predictive analytics, and real-time data monitoring are transforming the way vehicles are designed, produced, and maintained.\n",
    "\n",
    "    - **BMW‚Äôs Use of Digital Twin and Smart Factory:** BMW has integrated Digital Twin technology into its smart factories, where virtual representations of physical production lines and vehicles are created. These digital replicas are continuously updated with real-time data from the physical world, allowing BMW to monitor and optimize the production process. Any deviation from the expected conditions (such as equipment malfunctions or production delays) can be detected and addressed proactively.\n",
    "    \n",
    "    - **Tesla‚Äôs Agile Manufacturing with MBSE:** Tesla‚Äôs production lines are renowned for their agility, and MBE plays a crucial role in making this possible. Tesla uses virtual prototypes and simulation models to rapidly iterate on vehicle designs and manufacturing processes. Additionally, Tesla‚Äôs real-time feedback loops ensure that production data is continuously fed back into the system to improve future iterations of the design and manufacturing process.\n",
    "    \n",
    "    - **Benefits:**\n",
    "      - Enhanced flexibility and faster time-to-market.\n",
    "      - Greater accuracy and precision in production.\n",
    "      - Reduced downtime due to predictive maintenance and real-time monitoring.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <a href=\"https://www.youtube.com/watch?v=g78YHYXXils\" target=\"_blank\">\n",
    "        <img src=\"https://img.youtube.com/vi/g78YHYXXils/0.jpg\" alt=\"Video Thumbnail\" width=\"560\" height=\"315\" />\n",
    "    </a>\n",
    "</div>\n",
    "\n",
    "\n",
    "- **AI-Powered Predictive Quality in Production Lines:** Both in the automotive and manufacturing sectors, AI is playing a major role in ensuring high quality while minimizing waste. By integrating AI algorithms into production lines, manufacturers can predict potential quality issues before they occur, ensuring products meet stringent standards and reducing the need for rework.\n",
    "\n",
    "    - **Predictive Analytics for Quality Control:** AI-powered systems are being used to monitor key parameters like temperature, pressure, and material quality in real time during production. For example, BMW uses AI to analyze sensor data from its production lines and predict potential defects before they affect the product. This helps reduce waste, improve product consistency, and increase throughput.\n",
    "    \n",
    "    - **Real-Time Adjustments in Production:** AI also allows manufacturers to make real-time adjustments to the production process. For example, if the system detects that a production line is deviating from optimal conditions, it can automatically adjust machine settings, material inputs, or other parameters to ensure the final product remains within quality standards.\n",
    "    \n",
    "    - **Automotive Industry Applications:** For companies like Tesla, AI-driven quality control is integrated directly into the manufacturing process, ensuring that vehicles are free of defects before they are shipped to customers. AI systems are used to inspect the paint quality, alignment, and performance of individual vehicle components during the production process, ensuring a higher level of precision and minimizing human error.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 3.9 **Conclusion & Next Steps**\n",
    "\n",
    "The journey toward mastering **Model-Based Enterprise (MBE)** is both exciting and challenging, as it requires the integration of cutting-edge technologies, frameworks, and methodologies. As industries continue to evolve, embracing MBE not only optimizes processes but also positions organizations for **sustainable innovation** and **competitive advantage**.\n",
    "\n",
    "### <font color = '#646464'>3.9.1 Mastering MBE Requires Continuous Learning and Adaptation to New Technologies</font>\n",
    "\n",
    "- **Adapting to Technological Advancements:** As digital transformation accelerates, MBE methodologies must evolve to leverage the latest tools and innovations. Mastering MBE is not a one-time achievement; it requires a mindset of continuous improvement and an openness to adopting emerging technologies such as AI, Machine Learning, Blockchain, and Digital Twins. Organizations must invest in ongoing training and knowledge sharing to keep pace with rapid technological advancements and ensure their teams are well-equipped to implement MBE effectively.\n",
    "\n",
    "- **Integration with Emerging Technologies:** The ability to integrate MBE with technologies such as Industry 4.0, IoT, and AI is crucial for staying competitive. For example, Digital Twins and AI-driven automation are enhancing the capabilities of MBE, improving everything from real-time product monitoring to predictive maintenance. As manufacturing and design environments become increasingly interconnected, staying current with these technologies will be key to reaping the full benefits of MBE.\n",
    "\n",
    "- **Continuous Professional Development:** The complexity of MBE means that professionals must stay up-to-date with new software tools, standards, and techniques. Many professionals will seek advanced certifications and training in MBSE, PLM, IoT, and other related fields to remain competitive in the industry.\n",
    "\n",
    "---\n",
    "\n",
    "### **Industry 4.0 and AI Will Further Enhance MBE Capabilities in the Coming Years**\n",
    "\n",
    "- **The Role of Industry 4.0:** The future of MBE is closely tied to the evolution of Industry 4.0, which introduces smart factories, automation**, and connected systems. This transformation allows for real-time data exchange, increased collaboration across teams, and more efficient decision-making. Industry 4.0 promises to enhance MBE by introducing innovations like AI-powered manufacturing, real-time analytics, and the Internet of Things (IoT), which will continuously improve design, manufacturing, and operational processes.\n",
    "\n",
    "- **AI & Machine Learning‚Äôs Impact:** The application of AI and Machine Learning (ML) to MBE will continue to reshape how companies develop products. AI can automate many of the repetitive tasks traditionally handled manually, such as validating design rules, performing simulations, and optimizing production schedules. Additionally, predictive analytics driven by AI will provide real-time insights into the performance and health of products, enabling faster decision-making and improving lifecycle management. The ability of AI to handle large datasets and perform complex analyses will significantly enhance the effectiveness of MBE.\n",
    "\n",
    "- **Autonomous Systems and AI Integration:** In the coming years, AI will likely integrate even more deeply into MBE processes, allowing for fully autonomous design optimization, manufacturing, and maintenance schedules. As AI systems learn from past data, they will be able to identify hidden patterns and optimize processes that would otherwise take human teams much longer to detect. This will lead to increased efficiency, lower costs, and improved product quality across various sectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad6141",
   "metadata": {
    "tags": [
     "Bottom Navigation"
    ]
   },
   "source": [
    "### <center>[‚óÄÔ∏é Module 2](Module2.ipynb)‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ[üè† Home](../../welcomePage.ipynb)‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ[Module 4 ‚ñ∂Ô∏é](Module4.ipynb)</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}