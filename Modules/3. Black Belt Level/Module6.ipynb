{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04aaf80e",
   "metadata": {
    "tags": [
     "auto-generated-toc"
    ]
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [B6 Digital Twins](#B6-Digital-Twins)\n",
    "  - [6.1 User Story 1](#6.1-User-Story-1)\n",
    "  - [6.2 User Story 2](#6.2-User-Story-2)\n",
    "- [üè† Home](../../welcomePage.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6619d-4846-4f20-9c3e-eb1c85be70e2",
   "metadata": {},
   "source": [
    "# B6 Digital Twins\n",
    "As introduced at the Green Belt level, constructing a digital twin requires a structured approach involving specific techniques and sequential steps. This section provides a detailed overview, accompanied by relevant code examples, to illustrate the implementation of digital twin technology.\n",
    "\n",
    "## 6.1 User Story 1\n",
    "**Additive Scanning Subtractive**\n",
    "### <font color = '#646464'>6.1.1 Preliminary definitions</font>\n",
    "\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_1.png\" alt=\"Drawing\" style=\"width: 600px;\" title=\"1\"/>\n",
    "\n",
    "\n",
    "### <font color = '#646464'>6.1.2 Variables</font>\n",
    "* MaxCuttingDepth: The closest we allow the cutting tool to the printing bed in mm\n",
    "* PassDepth: The depth of one cutting pass per revovlution in mm\n",
    "* FeedRate: The traveling speed of the cutting tool in mm/min\n",
    "* ToolThreeStartingLocation: The reference point of tool 3's starting location (X in mm, Y in mm)\n",
    "* Scale_factor: The scaling factor in percentage of original stl file compared to printed part\n",
    "* PixelsToFill: The amount of absent pixels to fill when processing scanner data\n",
    "* scannerResolution: The dimensions of each individual pixel in the scanner data in mm\n",
    "* ToolRadius: The radius of the cutting tool in mm\n",
    "* ToolClearenceHeight: Distance to lower printing bed durring cutting tool entry and exit in mm\n",
    "* ScanningClearence: The Z-axis offset from scanner to produce accurate scans in mm\n",
    "* SearchRadius: The distance from currently selected reference point to search for new line segments to generate cutting path in mm\n",
    "\n",
    "##### **File Path's**\n",
    "* Location's for each file to download and upload data to the printer, scanner, and data processing functions.\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to call the required Python libraries and add the file path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085a7b0-f9bb-43f5-b266-4bd38995efa5",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import trimesh\n",
    "import trimesh.path\n",
    "\n",
    "from shapely.geometry import Polygon, MultiPolygon, GeometryCollection, MultiLineString, Point, CAP_STYLE, JOIN_STYLE, LineString, LinearRing\n",
    "from shapely.ops import linemerge, unary_union, transform\n",
    "from shapely.affinity import rotate\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import find_objects, binary_erosion, label, binary_dilation\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "from skimage.measure import find_contours\n",
    "from skimage import measure\n",
    "\n",
    "from sympy import Point \n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "MaxCuttingDepth = 1 #The closest we allow the cutting tool to the printing bed in mm\n",
    "PassDepth = 3 #The depth of one cutting pass per revovlution in mm \n",
    "FeedRate = 500 #The traveling speed of the cutting tool in mm/min\n",
    "ToolThreeStartingLocation = (300, 200) #The reference point of tool 3's starting location (X in mm, Y in mm)\n",
    "scale_factor = 1 #The scaling factor in percentage of original stl file compared to printed part\n",
    "PixelsToFill = 20 #The amount of absent pixels to fill when processing scanner data\n",
    "scannerResolution = 0.02 #The dimensions of each individual pixel in the scanner data in mm\n",
    "ToolRadius = 1.5 #The radius of the cutting tool in mm\n",
    "ToolClearenceHeight = 10 #Distance to lower printing bed durring cutting tool entry and exit in mm\n",
    "ScanningClearence = 22 #The Z-axis offset from scanner to produce accurate scans in mm\n",
    "SearchRadius = 2 #The distance from currently selected reference point to search for new line segments to generate cutting path in mm\n",
    "\n",
    "stl_file_path = 'Module 6 Content/Stl/40by25Mv4.stl'\n",
    "g_code_file_path = 'Module 6 Content/GCode/40by25Mv5.gcode'\n",
    "scan_file_path = 'Module 6 Content/DataProcessing/Scan/scannerOutput1.csv'\n",
    "OutputFileName = \"test1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e6934-6f0e-45ff-89d8-75a5b5d8a8fb",
   "metadata": {},
   "source": [
    "##### **Functions**\n",
    "* Data processing \n",
    "* Exporting and receiving data from printer and scanner\n",
    "* Cutting path generation logic\n",
    "* G-code generation and export\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to define the functions needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ea2fb-227c-4062-8430-a2c0ef6deab5",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Functions for Processing Scanned CSV file\n",
    "def change_to_one(x):\n",
    "    if pd.notna(x) and isinstance(x, (int, float)):\n",
    "        return 1\n",
    "    return x\n",
    "\n",
    "def fill_nans_between_ones_row(arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "        row = arr[i]\n",
    "        ones_indices = np.where(row == 1)[0]\n",
    "        for j in range(len(ones_indices) - 1):\n",
    "            start, end = ones_indices[j], ones_indices[j + 1]\n",
    "            if np.isnan(row[start:end]).sum() <= PixelsToFill:\n",
    "                row[start:end] = np.nan_to_num(row[start:end], nan=1)\n",
    "        arr[i] = row\n",
    "    return arr\n",
    "\n",
    "def fill_nans_between_ones_col(arr):\n",
    "    for i in range(arr.shape[1]):\n",
    "        col = arr[:, i]\n",
    "        ones_indices = np.where(col == 1)[0]\n",
    "        for j in range(len(ones_indices) - 1):\n",
    "            start, end = ones_indices[j], ones_indices[j + 1]\n",
    "            if np.isnan(col[start:end]).sum() <= PixelsToFill:\n",
    "                col[start:end] = np.nan_to_num(col[start:end], nan=1)\n",
    "        arr[:, i] = col\n",
    "    return arr\n",
    "\n",
    "def keep_largest_body(arr):\n",
    "    structure = np.ones((3, 3))  \n",
    "    labeled_array, num_features = label(arr == 1, structure=structure)\n",
    "    sizes = np.bincount(labeled_array.ravel())\n",
    "    sizes[0] = 0  \n",
    "    largest_body_label = sizes.argmax()\n",
    "    largest_body_mask = labeled_array == largest_body_label\n",
    "    arr[~largest_body_mask & (arr == 1)] = np.nan\n",
    "    return arr\n",
    "\n",
    "\n",
    "#functions for communicating with printer/scanner \n",
    "\n",
    "# Function to connect with password\n",
    "def connect_with_password(password):\n",
    "    rr_connect_url = f\"{base_url}/rr_connect?password={password}\"\n",
    "    connect_response = requests.get(rr_connect_url)\n",
    "    \n",
    "    if connect_response.status_code == 200:\n",
    "        print(\"Connected successfully\")\n",
    "    else:\n",
    "        print(f\"Failed to connect: {connect_response.status_code}\")\n",
    "        print(connect_response.text)\n",
    "    return connect_response.status_code == 200\n",
    "\n",
    "# Function to insert additional line after the last G command that doesn't have a ';' before it\n",
    "def insert_line_after_last_g_command(file_path, additional_line):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Find the last G command that doesn't have a ';' before it\n",
    "    last_g_command_index = -1\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        if line.startswith('G') and not line.startswith(';'):\n",
    "            last_g_command_index = i\n",
    "    \n",
    "    # Insert the additional line after the found G command\n",
    "    if last_g_command_index != -1:\n",
    "        lines.insert(last_g_command_index + 1, additional_line + '\\n')\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Function to send the modified G-code file\n",
    "def send_gcode_file(file_path):\n",
    "    filename = file_path.split('/')[-1]  # Extract filename from path\n",
    "    upload_url = f\"{base_url}/rr_upload?name=/gcodes/{filename}\"\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        response = requests.post(upload_url, data=file)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"G-code file sent successfully\")\n",
    "        return filename\n",
    "    else:\n",
    "        print(f\"Failed to send G-code file: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Function to send a G-code command\n",
    "def send_gcode_command(command):\n",
    "    rr_gcode_url = f\"{base_url}/rr_gcode?gcode={command}\"\n",
    "    response = requests.get(rr_gcode_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"G-code command '{command}' sent successfully\")\n",
    "    else:\n",
    "        print(f\"Failed to send G-code command '{command}': {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "# Function to wait for the \"heater\" status to be 0 in the bed temperature\n",
    "def wait_for_heater_off(base_url, interval=1):\n",
    "    rr_status_url = f\"{base_url}/rr_status?type=1\"\n",
    "    print(f\"Constructed status URL: {rr_status_url}\")  \n",
    "    \n",
    "    # Wait for 120 seconds before starting the check\n",
    "    print(\"Waiting for 120 seconds before starting the check...\")\n",
    "    time.sleep(120)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(rr_status_url)\n",
    "            if response.status_code == 200:\n",
    "                status_data = response.json()\n",
    "                #print(f\"Status data received: {status_data}\")\n",
    "                if 'temps' in status_data and 'bed' in status_data['temps'] and status_data['temps']['bed']['state'] == 0:\n",
    "                    print(\"Heater state is 0, stopping.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Failed to get status: {response.status_code}\")\n",
    "                print(response.text)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(f\"Connection error: {e}\")\n",
    "        \n",
    "        time.sleep(interval)\n",
    "\n",
    "        \n",
    "# functions for generating cutting path\n",
    "# Function to find the closest point\n",
    "def find_closest_point(point, segments):\n",
    "    min_dist = float('inf')\n",
    "    closest_segment = None\n",
    "    closest_point = None\n",
    "    for segment in segments:\n",
    "        for pt in segment:\n",
    "            dist = point.distance(Point(pt))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_segment = segment\n",
    "                closest_point = pt\n",
    "    return closest_segment, closest_point\n",
    "\n",
    "# Convert the resulting lines to coordinate arrays without merging them\n",
    "def lines_to_coords(geom):\n",
    "    if isinstance(geom, LineString):\n",
    "        return [np.array(geom.coords)]\n",
    "    elif isinstance(geom, MultiLineString):\n",
    "        return [np.array(line.coords) for line in geom.geoms]\n",
    "    elif hasattr(geom, 'geoms'):  # Handle other collections of geometries\n",
    "        coords = []\n",
    "        for line in geom.geoms:\n",
    "            coords.append(np.array(line.coords))\n",
    "        return coords\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def offset_lines(segments, offset_distance):\n",
    "    offset_segments = []\n",
    "    for segment in segments:\n",
    "        line = LineString(segment)\n",
    "        offset_line = line.parallel_offset(offset_distance, 'left')\n",
    "        if isinstance(offset_line, MultiLineString):\n",
    "            for offset_part in offset_line:\n",
    "                offset_segments.append(np.array(offset_part.coords))\n",
    "        else:\n",
    "            offset_segments.append(np.array(offset_line.coords))\n",
    "    return offset_segments\n",
    "\n",
    "# Function to filter and adjust line segments\n",
    "def filter_and_adjust_line_segments(polygon, segments):\n",
    "    filtered_segments = []\n",
    "    for segment in segments:\n",
    "        # Convert numpy array to list of tuples\n",
    "        line = LineString(segment.tolist())\n",
    "        \n",
    "        # Split the line by the polygon boundary\n",
    "        difference = line.difference(polygon)\n",
    "        \n",
    "        # Handle different geometries that might result from the split\n",
    "        if difference.geom_type == 'LineString':\n",
    "            if not polygon.contains(difference):\n",
    "                filtered_segments.append(np.array(difference.coords))\n",
    "        elif difference.geom_type == 'MultiLineString':\n",
    "            for part in difference.geoms:\n",
    "                if not polygon.contains(part):\n",
    "                    filtered_segments.append(np.array(part.coords))\n",
    "        elif difference.geom_type == 'GeometryCollection':\n",
    "            for part in difference:\n",
    "                if part.geom_type == 'LineString' and not polygon.contains(part):\n",
    "                    filtered_segments.append(np.array(part.coords))\n",
    "    \n",
    "    # Filter out any empty arrays\n",
    "    filtered_segments = [seg for seg in filtered_segments if seg.size > 0]\n",
    "    \n",
    "    return filtered_segments\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "def segment_length(segment):\n",
    "    return distance(segment[0], segment[1])\n",
    "\n",
    "def total_length(segments):\n",
    "    return sum(segment_length(seg) for seg in segments)\n",
    "\n",
    "def percent_difference(original_length, new_length):\n",
    "    return abs(original_length - new_length) / original_length * 100\n",
    "\n",
    "def closest_point(point, segments, used_segments):\n",
    "    closest_p = None\n",
    "    closest_seg = None\n",
    "    min_dist = float('inf')\n",
    "    for seg in segments:\n",
    "        if tuple(map(tuple, seg)) in used_segments:\n",
    "            continue\n",
    "        for p in [seg[0], seg[1]]:\n",
    "            dist = distance(point, p)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_p = p\n",
    "                closest_seg = seg\n",
    "    return closest_p, closest_seg\n",
    "\n",
    "def add_segment(new_list, segment, point, used_segments):\n",
    "    if np.array_equal(point, segment[0]):\n",
    "        new_list.append(segment)\n",
    "    else:\n",
    "        new_list.append(segment[::-1])\n",
    "    used_segments.add(tuple(map(tuple, segment)))\n",
    "\n",
    "def find_segments_with_starting_segment(start_segment, L1, L2):\n",
    "    new_list = []\n",
    "    used_segments = set()\n",
    "    \n",
    "    P1 = start_segment[1]  # Use the last point of the start segment as the starting point\n",
    "    add_segment(new_list, start_segment, start_segment[0], used_segments)\n",
    "    \n",
    "    while len(used_segments) < len(L1) + len(L2) - 1:\n",
    "        # Determine current and opposite lists based on the location of P1\n",
    "        if any(np.array_equal(P1, seg[0]) or np.array_equal(P1, seg[1]) for seg in L1):\n",
    "            current_list = L1\n",
    "            opposite_list = L2\n",
    "        else:\n",
    "            current_list = L2\n",
    "            opposite_list = L1\n",
    "        \n",
    "        # Find closest point and segment from the opposite list\n",
    "        P2, S2 = closest_point(P1, opposite_list, used_segments)\n",
    "        if S2 is None:\n",
    "            break\n",
    "        \n",
    "        P4 = S2[1] if np.array_equal(P2, S2[0]) else S2[0]\n",
    "        \n",
    "        # Find closest point and segment from the current list\n",
    "        P3, S3 = closest_point(P1, current_list, used_segments)\n",
    "        if S3 is None:\n",
    "            break\n",
    "        \n",
    "        P6 = S3[1] if np.array_equal(P3, S3[0]) else S3[0]\n",
    "        \n",
    "        # Check distances\n",
    "        dist_P2 = distance(P1, P2)\n",
    "        dist_P3 = distance(P1, P3)\n",
    "        \n",
    "        # If P2 is out of range (>3mm) and P3 is in range (<=3mm)\n",
    "        if dist_P2 > SearchRadius and dist_P3 <= SearchRadius :\n",
    "            add_segment(new_list, S3, P3, used_segments)\n",
    "            P1 = P6\n",
    "        # If P3 is out of range (>3mm) and P2 is in range (<=3mm)\n",
    "        elif dist_P3 > SearchRadius and dist_P2 <= SearchRadius :\n",
    "            add_segment(new_list, S2, P2, used_segments)\n",
    "            P1 = P4\n",
    "        # If both P2 and P3 are in range (<=3mm)\n",
    "        else:\n",
    "            P5, _ = closest_point(P4, current_list, used_segments)\n",
    "            if np.array_equal(P3, P5):\n",
    "                add_segment(new_list, S2, P2, used_segments)\n",
    "                P1 = P4\n",
    "            else:\n",
    "                add_segment(new_list, S3, P3, used_segments)\n",
    "                P1 = P6\n",
    "    \n",
    "    # Add the last remaining segment\n",
    "    remaining_segments = [seg for seg in L1 + L2 if tuple(map(tuple, seg)) not in used_segments]\n",
    "    if len(remaining_segments) == 1:\n",
    "        last_segment = remaining_segments[0]\n",
    "        last_point = P1\n",
    "        add_segment(new_list, last_segment, last_point, used_segments)\n",
    "    \n",
    "    return new_list, used_segments\n",
    "\n",
    "def find_best_starting_segment(L1, L2):\n",
    "    original_total_length = total_length(L1) + total_length(L2)\n",
    "    best_segments = []\n",
    "    best_length_diff = float('inf')\n",
    "    all_results = []\n",
    "    \n",
    "    for start_segment in L1 + L2:\n",
    "        new_list, _ = find_segments_with_starting_segment(start_segment, L1, L2)\n",
    "        new_list_length = total_length(new_list)\n",
    "        pct_diff = percent_difference(original_total_length, new_list_length)\n",
    "        \n",
    "        all_results.append((pct_diff, new_list))\n",
    "        \n",
    "        #print(f\"Starting segment: {start_segment}\")\n",
    "        #print(f\"New list total length: {new_list_length:.2f}\")\n",
    "        #print(f\"Percent difference: {pct_diff:.2f}%\")\n",
    "        \n",
    "        if pct_diff < best_length_diff:\n",
    "            best_segments = new_list\n",
    "            best_length_diff = pct_diff\n",
    "    \n",
    "    # Find the list with the closest total length to the original total length\n",
    "    all_results.sort(key=lambda x: x[0])\n",
    "    \n",
    "    print(\"\\nPath Generated\")\n",
    "    #print(f\"Percent difference: {all_results[0][0]:.2f}%\")\n",
    "    \n",
    "    return all_results[0][1]\n",
    "\n",
    "def extract_points_from_segments(merged_path):\n",
    "\n",
    "    points = []\n",
    "    \n",
    "    \n",
    "    for segment in merged_path:\n",
    "        for point in segment:\n",
    "            points.append(point)\n",
    "    \n",
    "    # Convert the list of points to a numpy array\n",
    "    points_array = np.array(points)\n",
    "    return points_array\n",
    "\n",
    "\n",
    "# Functions for taking cutting path and converting it into coordinates\n",
    "\n",
    "def convert_line_string_to_2d_array(line_string: LineString) -> np.ndarray:\n",
    "    # Extract coordinates from the LineString object\n",
    "    coords = list(line_string.coords)\n",
    "    \n",
    "    # Convert tuples to list of lists and then to a 2D NumPy array\n",
    "    result = np.array([list(coord) for coord in coords])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def find_closest_coordinate(coordinates: np.ndarray, reference: Tuple[float, float]) -> Tuple[int, Tuple[float, float]]:\n",
    "    # Debugging information\n",
    "    print(f\"Coordinates type: {type(coordinates)}\")\n",
    "    print(f\"Coordinates shape: {coordinates.shape}\")\n",
    "    \n",
    "    if not isinstance(coordinates, np.ndarray) or coordinates.ndim != 2 or coordinates.shape[1] != 2:\n",
    "        raise ValueError(\"Coordinates must be a 2D NumPy array with shape (n, 2).\")\n",
    "    \n",
    "    reference_array = np.array(reference)\n",
    "    \n",
    "    distances = np.sqrt(np.sum((coordinates - reference_array) ** 2, axis=1))\n",
    "    min_index = np.argmin(distances)\n",
    "    closest_coordinate = tuple(coordinates[min_index])\n",
    "    \n",
    "    return int(min_index), closest_coordinate\n",
    "\n",
    "def find_closest_index(array, value):\n",
    "    # Calculate the Euclidean distance between each row and the value\n",
    "    distances = np.linalg.norm(array - value, axis=1)\n",
    "    # Return the index of the minimum distance\n",
    "    return np.argmin(distances)\n",
    "\n",
    "def rearrange_2d_array(array, start_value):\n",
    "    # Flatten the 2D array to 1D\n",
    "    flat_array = array.reshape(-1, array.shape[-1])\n",
    "    \n",
    "    # Find the closest index of the start value\n",
    "    start_index = find_closest_index(flat_array, start_value)\n",
    "    \n",
    "    # Rearrange the flat array to start from the start index\n",
    "    rearranged_array = np.vstack((flat_array[start_index:], flat_array[:start_index]))\n",
    "    \n",
    "    # Reshape the 1D array back to 2D array with original shape\n",
    "    reshaped_array = rearranged_array.reshape(array.shape)\n",
    "    \n",
    "    return reshaped_array\n",
    "\n",
    "\n",
    "#Functions to convert coordinates into Gcode\n",
    "\n",
    "# Function to print the specified pattern\n",
    "def print_pattern(G, F, Z_start, Z_end, array):\n",
    "    output = []\n",
    "    Z = Z_start\n",
    "    while Z >= Z_end:\n",
    "        for pair in array:\n",
    "            X, Y = pair\n",
    "            output.append(f\"G{G} X{round(X, 3)} Y{round(Y, 3)} Z{round(Z, 3)} F{F}\")\n",
    "        Z -= PassDepth\n",
    "    return output\n",
    "        \n",
    "\n",
    "# Function to print the additional specified format\n",
    "def print_start_format(ref_point, Z_var, array):\n",
    "    outputStart = []\n",
    "    ref_X, ref_Y = ref_point\n",
    "    Z_value = round(Z_var + ToolClearenceHeight, 3)\n",
    "    first_X, first_Y = array[0]\n",
    "    \n",
    "    outputStart.append(\"G1 U0 V-50 F1000 ; Move scanner back to starting location\")\n",
    "    outputStart.append(\"G21 ; set units to millimeters\")\n",
    "    outputStart.append(\"G90 ; use absolute coordinates\")\n",
    "    outputStart.append(\"T-1 ; Clear tool selection\")\n",
    "    outputStart.append(\"T3 ; Pick up subtractive tool\")\n",
    "    outputStart.append(\"M98 P/macros/InitializeServo1 ; Turn on subtractive tool\")\n",
    "    outputStart.append(f\"G1 X{round(ref_X, 3)} Y{round(ref_Y, 3)} Z{Z_value} F{F}\")\n",
    "    outputStart.append(f\"G1 X{round(first_X, 3)} Y{round(first_Y, 3)} Z{Z_value} F{F}\")\n",
    "    return outputStart\n",
    "\n",
    "# Function to print the additional specified format\n",
    "def print_end_format(ref_point, Z_var, array):\n",
    "    outputEnd = []\n",
    "    ref_X, ref_Y = ref_point\n",
    "    Z_value = round(Z_var + 10, 3)\n",
    "    first_X, first_Y = array[0]\n",
    "    \n",
    "    outputEnd.append(f\"G1 X{round(first_X, 3)} Y{round(first_Y, 3)} Z{Z_value} F{F}\")\n",
    "    outputEnd.append(f\"G1 X{round(ref_X, 3)} Y{round(ref_Y, 3)} Z{Z_value} F{F}\")\n",
    "    outputEnd.append(\"T-1 ; Turn off and put tool away\")\n",
    "    return outputEnd\n",
    "\n",
    "#Functions for exporting compiled subtractive g code \n",
    "\n",
    "\n",
    "# Function to connect with password\n",
    "def connect_with_password(password):\n",
    "    try:\n",
    "        rr_connect_url = f\"{base_url}/rr_connect?password={password}\"\n",
    "        connect_response = requests.get(rr_connect_url)\n",
    "        \n",
    "        if connect_response.status_code == 200:\n",
    "            logging.info(\"Connected successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            logging.error(f\"Failed to connect: {connect_response.status_code}\")\n",
    "            logging.error(connect_response.text)\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred during connection: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to save combined output to a G-code file\n",
    "def save_combined_output_to_file(combined_output, file_path):\n",
    "    try:\n",
    "        # Join list elements into a single string\n",
    "        combined_output_str = '\\n'.join(combined_output)\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(combined_output_str)\n",
    "        logging.info(f\"Combined output saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred while saving to file: {e}\")\n",
    "\n",
    "# Function to send the G-code file\n",
    "def send_gcode_file(file_path):\n",
    "    try:\n",
    "        filename = os.path.basename(file_path)  # Extract filename from path\n",
    "        upload_url = f\"{base_url}/rr_upload?name=/gcodes/{filename}\"\n",
    "        \n",
    "        with open(file_path, 'rb') as file:\n",
    "            response = requests.post(upload_url, data=file)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            logging.info(\"G-code file sent successfully\")\n",
    "            return filename\n",
    "        else:\n",
    "            logging.error(f\"Failed to send G-code file: {response.status_code}\")\n",
    "            logging.error(response.text)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred while sending G-code file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to send a G-code command\n",
    "def send_gcode_command(command):\n",
    "    try:\n",
    "        rr_gcode_url = f\"{base_url}/rr_gcode?gcode={command}\"\n",
    "        response = requests.get(rr_gcode_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            logging.info(f\"G-code command '{command}' sent successfully\")\n",
    "        else:\n",
    "            logging.error(f\"Failed to send G-code command '{command}': {response.status_code}\")\n",
    "            logging.error(response.text)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred while sending G-code command: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1694a-66bb-452b-bf4a-49e8cb54b7f4",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.1.3 Digital Modeling</font>\n",
    "##### **Importing STL file and creating 3D reference model**\n",
    "* Taking a cross section to create a refrence plane\n",
    "* From refrence plane create a boundary off of the exterior profile\n",
    "* Compute the X, Y, and Z offset to find the parts location on printing bed and height of model\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to import STL file and create 3D reference model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8aca9-3b3a-4329-acd2-257613b496b5",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mesh = trimesh.load_mesh(stl_file_path)  \n",
    "mesh.apply_scale(scale_factor)\n",
    "xOffset = mesh.bounds[0,0]+ (0.5*(mesh.bounds[1,0]-mesh.bounds[0,0]))\n",
    "yOffset = mesh.bounds[0,1]+ (0.5*(mesh.bounds[1,1]-mesh.bounds[0,1]))\n",
    "PartHeight = mesh.bounds[1,2]\n",
    "#print(\"Initial bounding box dimensions:\", mesh.bounds)\n",
    "#print(\"Scaled bounding box dimensions:\", mesh.bounds)\n",
    "print(f\"X Offset = {xOffset}, Y Offset = {yOffset} Z Max = {PartHeight}\")\n",
    "Profile2d = trimesh.path.polygons.projected(mesh,[0,0,1],origin=None, ignore_sign=True, rpad=1e-05, apad=None, tol_dot=0.01,) # max_regions=200\n",
    "#trimesh.path.polygons.plot(polygon=Profile2d, show=True, axes=None)\n",
    "originalVertices = np.array(Profile2d.exterior.coords)\n",
    "shape = trimesh.Scene(mesh,'world')\n",
    "trimesh.Scene.show(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60907095-0142-4bc0-9d00-30156e13572d",
   "metadata": {},
   "source": [
    "##### **Exporting original Gcode**\n",
    "* Adds the commands to center scanner over printed part once printing is completed\n",
    "* Sends updated G-code to printer to start additive process\n",
    "\n",
    "def main():\n",
    "    password = \"your_password\"  \n",
    "    gcode_file_path = g_code_file_path  # Path to the uploaded file\n",
    "\n",
    "    # Calculate the Z height\n",
    "    z_height = PartHeight + ScanningClearence\n",
    "\n",
    "    # Additional line to add to the G-code file\n",
    "    additional_line = f\"G1 U152.5 V232 Z{z_height}\"  # Use the calculated Z height\n",
    "\n",
    "    # Connect with password\n",
    "    if connect_with_password(password):\n",
    "        # Insert the additional line after the last G command that doesn't have a ';' before it\n",
    "        insert_line_after_last_g_command(gcode_file_path, additional_line)\n",
    "        # Send the modified G-code file\n",
    "        filename = send_gcode_file(gcode_file_path)\n",
    "        if filename:\n",
    "            # Send M23 command to select the file\n",
    "            send_gcode_command(f\"M23 {filename}\")\n",
    "            # Send M24 command to start the print\n",
    "            send_gcode_command(\"M24\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "##### **Automation process to delay scanner from operating till additive process has finished**\n",
    "if __name__ == \"__main__\":  \n",
    "    wait_for_heater_off(base_url)\n",
    "\n",
    "##### **Activating Gocator Scanner**\n",
    "* Triggers scanner and deposites buffer into holding file\n",
    "\n",
    "output_file = 'AdditiveScanningSubtractive/DataProcessing/Buffer/testoutputbuffer.gprec'\n",
    "\n",
    "os.environ['WINEDEBUG'] = '-all'\n",
    "\n",
    "\n",
    "command = [\n",
    "    'wine', \n",
    "    './DataProcessing/RecordandDownload/ReplayData.exe',  \n",
    "    output_file,\n",
    "    scanner_ip_adress\n",
    "]\n",
    "\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "print(\"Output:\", result.stdout)\n",
    "print(\"Errors:\", result.stderr)\n",
    "print(\"Return code:\", result.returncode)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"Command executed successfully.\")\n",
    "else:\n",
    "    print(\"Command execution failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac2869-1cfc-4b1e-a55b-446a0875a3c2",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.1.4 Data Transmission</font>\n",
    "\n",
    "##### **Function to convert scanned file from .gprec to .csv for easier data processing**\n",
    "\n",
    "output_file = scan_file_path\n",
    "input_file = './DataProcessing/Buffer/testoutputbuffer2.gprec'\n",
    "if not os.path.isfile(input_file):\n",
    "    print(f\"Error: Input file {input_file} does not exist.\")\n",
    "else:\n",
    "    os.environ['WINEDEBUG'] = '-all'\n",
    "\n",
    "    \n",
    "    command = [\n",
    "        'wine', \n",
    "        './DataProcessing/ReplayConverter/ReplayConverter.exe', \n",
    "        '-i', input_file, \n",
    "        '-f', '0', \n",
    "        '-o', output_file\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Output:\", result.stdout)\n",
    "    print(\"Errors:\", result.stderr)\n",
    "    print(\"Return code:\", result.returncode)\n",
    "\n",
    "    # Check if the command ran successfully\n",
    "    if result.returncode == 0:\n",
    "        print(\"Command executed successfully.\")\n",
    "    else:\n",
    "        print(\"Command execution failed.\")\n",
    "\n",
    "##### **Processing scanner data**\n",
    "* Loading in scanned data as plain text then cleaning up data so that we are left with only the X,Y, and heightmap\n",
    "* Dropping all of the rows and columns that are left blank to reduce file size\n",
    "* Taking the height map and replacing any real values with 1's so that we are left with \"NaN's\" and \"1's\" to ease data processing\n",
    "* Sorting through the clusters of 1's and finding the largest independent island and removing all other clusters to isolate the part.\n",
    "* Filling in the empty NaN spaces that fall between two 1's befor: [ 1 NaN NaN NaN NaN 1 ], after: [ 1 1 1 1 1 1 ]\n",
    "* Repeating this process through all of the rows and then columns\n",
    "* Output the heightmap with only the isolated part data that has been cleaned\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_2.png\" alt=\"Drawing\" style=\"width: 500px;\" title=\"2\"/>\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_3.png\" alt=\"Drawing\" style=\"width: 500px;\" title=\"3\"/>\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to convert scanned file and process the scanner data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479f0a4-44d6-41d3-8ce1-de885ccc3440",
   "metadata": {
    "has_explanation": false
   },
   "outputs": [],
   "source": [
    "with open(scan_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "scanned_data = [line.strip().split(',') for line in lines]\n",
    "\n",
    "\n",
    "scanned = pd.DataFrame(scanned_data)\n",
    "                          \n",
    "#Clean dataframe\n",
    "scanned = scanned.iloc[27:]\n",
    "scanned = scanned.apply(pd.to_numeric, errors='ignore') \n",
    "cols_to_drop = scanned.columns[scanned.notna().sum() < 3]\n",
    "rows_to_drop = scanned.notna().sum(axis=1) < 3\n",
    "scanned = scanned.drop(columns=cols_to_drop)\n",
    "scanned = scanned[~rows_to_drop]\n",
    "scanned.columns = range(len(scanned.columns))\n",
    "scanned.reset_index(drop=True, inplace=True)\n",
    "#scanned\n",
    "\n",
    "#isolate Height Map\n",
    "xAxisArray = scanned.iloc[1,1:].to_numpy()\n",
    "yAxisArray = scanned.iloc[1:,0].to_numpy()\n",
    "heightMap = scanned.iloc[1:,1:].to_numpy()\n",
    "\n",
    "#Process Height Map \n",
    "scanned.iloc[1:, 1:] = scanned.iloc[1:, 1:].applymap(change_to_one)\n",
    "heightMapOne = scanned.iloc[1:,1:].to_numpy()\n",
    "heightMapSingle = keep_largest_body(heightMapOne)\n",
    "heightMapRow = fill_nans_between_ones_row(heightMapSingle)\n",
    "heightMapTotall = fill_nans_between_ones_col(heightMapRow)\n",
    "heightMapSingle = keep_largest_body(heightMapTotall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852acc14-d817-4bf6-963a-c69e33ad4488",
   "metadata": {},
   "source": [
    "##### **Visualizing scanned file pre and post data processing**\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to show the scanned file pre and post data processing visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71309ac3-c18b-42ca-84e4-78ede032b20f",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 11))\n",
    "plt.title('Original Height Map')\n",
    "plt.imshow(heightMap.astype(float), cmap='viridis')  # 'viridis' is just an example colormap, you can choose others\n",
    "plt.colorbar()  # Add a color bar for reference\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 11))\n",
    "plt.title('Adjusted Height Map')\n",
    "plt.imshow(heightMapTotall, cmap='viridis')  # 'viridis' is just an example colormap, you can choose others\n",
    "plt.colorbar()  # Add a color bar for reference\n",
    "plt.show()\n",
    "\n",
    "threshold = 0.5\n",
    "heightMapSingle = np.where(heightMapSingle == None, np.nan, heightMapSingle).astype(float)\n",
    "binary_mask = heightMapRow > threshold\n",
    "\n",
    "plt.figure(figsize=(8, 11))\n",
    "plt.imshow(binary_mask, cmap='gray', interpolation='nearest')\n",
    "plt.show()\n",
    "contours = find_contours(binary_mask,0.5)\n",
    "boundary_points = np.concatenate(contours,)\n",
    "boundary_points = [(point[0], point[1]) for point in boundary_points]\n",
    "scannedShape = Polygon(boundary_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c13da-908d-4dd7-924d-e8ec1c8201c6",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.1.5 Physical to Virtual</font>\n",
    "##### **Creating a boundary based off of the scanner data and overlaying it with the boundary based off of the original part file**\n",
    "* Creating a boundary from the exterior shape of the scanned data\n",
    "* Overlay the scanned boundary with the original stl boundary created previously\n",
    "* Color code overlaping sections to identify defective sections\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_4.png\" alt=\"Drawing\" style=\"width: 700px;\" title=\"4\"/>\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_5.png\" alt=\"Drawing\" style=\"width: 500px;\" title=\"5\"/>\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to create the boundary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b85c77-c83e-4e5e-9e37-f9cb63ce0df6",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Rotating scanned shape\n",
    "scannedShape = rotate(scannedShape, 179.75, origin='center')\n",
    "#Scale the size of the scan by the scanner resolution:\n",
    "scannedShape = Polygon([(x * scannerResolution, y * scannerResolution) for x, y in scannedShape.exterior.coords])\n",
    "\n",
    "#Finds bounds of the scanned\n",
    "scannedShapeBounds = scannedShape.bounds\n",
    "xBound = scannedShapeBounds[0]+ (0.5*(scannedShapeBounds[2]-scannedShapeBounds[0]))\n",
    "yBound = scannedShapeBounds[1]+ (0.5*(scannedShapeBounds[3]-scannedShapeBounds[1]))\n",
    "# Move the polygon by applying the translation offsets so it lines up with the position of the part:\n",
    "scannedShape = Polygon([(x + xOffset-xBound, y + yOffset-yBound) for x, \n",
    "                        y in scannedShape.exterior.coords])\n",
    "\n",
    "x_coords, y_coords = scannedShape.exterior.xy\n",
    "# Plot the polygon\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(x_coords, y_coords, color='blue', alpha=0.7, linewidth=2, solid_capstyle='round', zorder=2)\n",
    "plt.fill(x_coords, y_coords, color='lightblue', alpha=0.5, zorder=1)\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "plt.title('Scanned Polygon Boundary')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Overlay the polygons\n",
    "overlay_polygon = scannedShape.difference(Profile2d)\n",
    "#overlay_polygon = Profile2d.difference(scannedShape)\n",
    "# Plot the polygons and overlay\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "# Plot polygon 1\n",
    "x1, y1 = Profile2d.exterior.xy\n",
    "ax.plot(x1, y1, color='blue', alpha=0.7, linewidth=2, label='STL Polygon')\n",
    "\n",
    "# Plot polygon 2\n",
    "x2, y2 = scannedShape.exterior.xy\n",
    "ax.plot(x2, y2, color='green', alpha=0.7, linewidth=2, label='Scanned Polygon')\n",
    "\n",
    "# Plot overlay polygon\n",
    "if isinstance(overlay_polygon, Polygon):\n",
    "    x_overlay, y_overlay = overlay_polygon.exterior.xy\n",
    "    ax.fill(x_overlay, y_overlay, color='red', alpha=0.5, label='Overlay')\n",
    "elif isinstance(overlay_polygon, MultiPolygon) or isinstance(overlay_polygon, GeometryCollection):\n",
    "    for geom in overlay_polygon.geoms:\n",
    "        if isinstance(geom, Polygon):\n",
    "            x_overlay, y_overlay = geom.exterior.xy\n",
    "            ax.fill(x_overlay, y_overlay, color='red', alpha=0.5)\n",
    "\n",
    "# Set plot attributes\n",
    "ax.set_title('Overlay of the Polygons')\n",
    "ax.set_xlabel('X (mm)')\n",
    "ax.set_ylabel('Y (mm)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dec53-a34f-486d-8940-3e34120008c5",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.1.6 Virtual to Physical</font>\n",
    "##### **Generating cutting path based off of identified defected sections of printed part**\n",
    "* Take the identified defective sections of the original boundary and offset them by the cutting tools radius creating a cutting segment\n",
    "* Take the non-defective sections of the original boundary and offset them by the cutting tools diameter creating a clearence segment\n",
    "* Store these in two seperate arrays for cutting path generation.\n",
    "* Take the two arrays and process them segment by segment using the cutting path logic defined\n",
    "* This logic orders the segments by finding the closest segments within a specified distance\n",
    "* Then determing which of these segments will lead to having all of the segments used from each array\n",
    "* The goal of this to create a singular path that uses all of the stored cutting segments and clearence segments withought crossing the original parts boundary.\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_6.png\" alt=\"Drawing\" style=\"width: 700px;\" title=\"6\"/>\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_7.png\" alt=\"Drawing\" style=\"width: 700px;\" title=\"7\"/>\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to generate cutting path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e5b96-e619-495a-888f-c4586e7d64e3",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Original shapes\n",
    "original_shape = Profile2d\n",
    "scanned_shape = scannedShape\n",
    "original_boundary = LineString(original_shape.exterior.coords)\n",
    "boundary_polygon = Polygon(original_boundary)\n",
    "# offsets\n",
    "original_shape_r = Profile2d.buffer(ToolRadius, cap_style=CAP_STYLE.flat, join_style=JOIN_STYLE.mitre)\n",
    "scanned_shape_r = scannedShape.buffer(ToolRadius, cap_style=CAP_STYLE.flat, join_style=JOIN_STYLE.mitre)\n",
    "original_shape_two_r = Profile2d.buffer(ToolRadius*2, cap_style=CAP_STYLE.flat, join_style=JOIN_STYLE.mitre)\n",
    "scanned_shape_two_r = scannedShape.buffer(ToolRadius*2, cap_style=CAP_STYLE.flat, join_style=JOIN_STYLE.mitre)\n",
    "\n",
    "original_boundary = LineString(original_shape.exterior.coords)\n",
    "intersection_lines = original_boundary.intersection(scanned_shape)\n",
    "within_bounds = original_boundary.intersection(scanned_shape)\n",
    "out_of_bounds = original_boundary.difference(within_bounds)\n",
    "\n",
    "original_boundary_r = LineString(original_shape_r.exterior.coords)\n",
    "intersection_lines_r = original_boundary_r.intersection(scanned_shape_r)\n",
    "within_bounds_r = original_boundary_r.intersection(scanned_shape_r)\n",
    "out_of_bounds_r = original_boundary_r.difference(within_bounds_r)\n",
    "\n",
    "original_boundary_two_r = LineString(original_shape_two_r.exterior.coords)\n",
    "intersection_lines_two_r = original_boundary_two_r.intersection(scanned_shape_two_r)\n",
    "within_bounds_two_r = original_boundary_two_r.intersection(scanned_shape_two_r)\n",
    "out_of_bounds_two_r = original_boundary_two_r.difference(within_bounds_two_r)\n",
    "\n",
    "boundary_within_bounds = lines_to_coords(within_bounds)\n",
    "boundary_out_of_bounds = lines_to_coords(out_of_bounds)\n",
    "\n",
    "boundary_within_bounds_r = lines_to_coords(within_bounds_r)\n",
    "boundary_out_of_bounds_r = lines_to_coords(out_of_bounds_r)\n",
    "\n",
    "boundary_within_bounds_two_r = lines_to_coords(within_bounds_two_r)\n",
    "boundary_out_of_bounds_two_r = lines_to_coords(out_of_bounds_two_r)\n",
    "\n",
    "offsetPolygon = Profile2d.buffer(2*ToolRadius*0.99)\n",
    "#print(boundary_out_of_bounds_two_r)\n",
    "#print(boundary_within_bounds_r)\n",
    "\n",
    "# Filter and adjust the line segments\n",
    "filtered_segments = filter_and_adjust_line_segments(offsetPolygon, boundary_out_of_bounds_two_r)\n",
    "\n",
    "# Print the results\n",
    "#print(\"Filtered and Adjusted Line Segments (On the border or outside):\")\n",
    "#for segment in filtered_segments:\n",
    "#    print(segment)\n",
    "\n",
    "result = find_best_starting_segment(filtered_segments, boundary_within_bounds_r)\n",
    "#print(\"Result segments:\")\n",
    "#for seg in result:\n",
    "#    print(seg)\n",
    "\n",
    "points_array = extract_points_from_segments(result)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547455b7-602a-4b50-bd93-a1de395fd010",
   "metadata": {},
   "source": [
    "##### **Visualizations of cutting path generation**\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to run the visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc3a70-0b9d-4753-baff-10d7dd62c4b4",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_segments(segments, color, label):\n",
    "    for segment in segments:\n",
    "        plt.plot(segment[:, 0], segment[:, 1], color=color, label=label)\n",
    "        label = \"_nolegend_\"  # Prevents duplicate labels in legend\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "# Plot the original boundary\n",
    "original_coords = np.array(original_boundary.coords)\n",
    "\n",
    "# Plot the within bounds segments\n",
    "plot_segments(boundary_within_bounds, 'r', 'Within Bounds')\n",
    "\n",
    "# Plot the out of bounds segments\n",
    "plot_segments(boundary_out_of_bounds, 'g', 'Out of Bounds')\n",
    "\n",
    "# Plot the offset out of bounds segments\n",
    "plot_segments(boundary_within_bounds_r, 'm', 'Offset Out of Bounds')\n",
    "\n",
    "# Plot the offset within bounds segments\n",
    "plot_segments(boundary_out_of_bounds_two_r, 'c', 'Offset Within Bounds')\n",
    "\n",
    "original_coordss = np.array(offsetPolygon.exterior.coords)\n",
    "\n",
    "# Display settings\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "plt.title('Boundary Segments with Offsets')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def plot_segments(segments, color, label):\n",
    "    for segment in segments:\n",
    "        plt.plot(segment[:, 0], segment[:, 1], color=color, label=label)\n",
    "        label = \"_nolegend_\"  \n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "# Plot the original boundary\n",
    "original_coords = np.array(original_boundary.coords)\n",
    "\n",
    "# Plot the within bounds segments\n",
    "plot_segments(boundary_within_bounds, 'r', 'Within Bounds')\n",
    "\n",
    "# Plot the out of bounds segments\n",
    "plot_segments(boundary_out_of_bounds, 'g', 'Out of Bounds')\n",
    "\n",
    "# Plot the offset out of bounds segments\n",
    "plot_segments(boundary_within_bounds_r, 'm', 'Offset Out of Bounds')\n",
    "\n",
    "# Plot the offset within bounds segments\n",
    "plot_segments(boundary_out_of_bounds_two_r, 'c', 'Offset Within Bounds')\n",
    "\n",
    "continuous_line_coords = np.array(points_array)\n",
    "plt.plot(continuous_line_coords[:, 0], continuous_line_coords[:, 1], 'b--', label='Continuous Line')\n",
    "\n",
    "\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "plt.title('Boundary Segments with Connected Offsets')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce1acc-8c52-4306-8e81-1cd8a55a126e",
   "metadata": {},
   "source": [
    "##### **Reordering cutting path based on milling tool location and converting the path from an ordered list of line segments and converting them into cartesian coordinates**\n",
    "* The outputted list of line segments need to be converted into a list coordinates to do this we break down each line segment into the points that they are comprised of\n",
    "* Then we take this new list of points and reorder them so that it starts at the point closest to the cutting tools location\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_8.png\" alt=\"Drawing\" style=\"width: 700px;\" title=\"8\"/>\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to reorder cutting path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d305d56-4c8f-45e5-8b32-883c9f4cf5b3",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reference = ToolThreeStartingLocation  # Reference point\n",
    "reference_polygon = Profile2d\n",
    "closest_index, closest = find_closest_coordinate(points_array, reference)\n",
    "# Call the function\n",
    "original_array = points_array\n",
    "start_value = closest\n",
    "rearranged_array = rearrange_2d_array(original_array, start_value)\n",
    "#print(rearranged_array)\n",
    "\n",
    "\n",
    "overlay_polygon = scannedShape.difference(Profile2d)\n",
    "\n",
    "# Plot the polygons and overlay\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# Plot polygon 1\n",
    "x1, y1 = Profile2d.exterior.xy\n",
    "ax.plot(x1, y1, color='c', alpha=0.7, linewidth=2, label='STL')\n",
    "\n",
    "# Plot polygon 2\n",
    "x2, y2 = scannedShape.exterior.xy\n",
    "ax.plot(x2, y2, color='m', alpha=0.7, linewidth=2, label='Scan')\n",
    "\n",
    "# Plot overlay polygon\n",
    "if isinstance(overlay_polygon, Polygon):\n",
    "    x_overlay, y_overlay = overlay_polygon.exterior.xy\n",
    "    ax.fill(x_overlay, y_overlay, color='red', alpha=0.5, label='Overlay')\n",
    "elif isinstance(overlay_polygon, MultiPolygon) or isinstance(overlay_polygon, GeometryCollection):\n",
    "    for geom in overlay_polygon.geoms:\n",
    "        if isinstance(geom, Polygon):\n",
    "            x_overlay, y_overlay = geom.exterior.xy\n",
    "            ax.fill(x_overlay, y_overlay, color='red', alpha=0.5)\n",
    "continuous_line_coords = rearranged_array\n",
    "#plt.plot(continuous_line_coords[:, 0], continuous_line_coords[:, 1], 'b-', label='Continuous Line')\n",
    "plt.plot(rearranged_array[:, 0], rearranged_array[:, 1], 'g', label='Cutting Path')\n",
    "\n",
    "# Set plot attributes\n",
    "ax.set_title('Ordered Cutting Path')\n",
    "ax.set_xlabel('X (mm)')\n",
    "ax.set_ylabel('Y (mm)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be1c46-7f7f-431f-94bd-658a01b35334",
   "metadata": {},
   "source": [
    "##### **Constructing G-Code**\n",
    "* Take the new list of points and convert them into a string of G-code commands\n",
    "* Refrencing the parts original height we use this as a starting height for the cutting path\n",
    "* Then we itterate the cutting path at decreasing heights determined by the path depth untill a minimum height is reached\n",
    "\n",
    "<img src=\"Module 6 Content/A_S_S_9.png\" alt=\"Drawing\" style=\"width: 700px;\" title=\"9\"/>\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to construct G-Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3fa3e-68fe-4695-a39f-5004d0b5275f",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "G = 1  # Replace with the actual G value\n",
    "F = FeedRate  # Replace with the actual F value\n",
    "StartingHeight = PartHeight\n",
    "Z_start = StartingHeight # Replace with the actual start value for Z\n",
    "Z_end = MaxCuttingDepth    # Replace with the actual end value for Z\n",
    "\n",
    "# Reference point for X and Y\n",
    "ref_point = ToolThreeStartingLocation  # Replace with the actual reference X and Y values\n",
    "Z_var = StartingHeight  # Replace with the actual Z variable value\n",
    "\n",
    "# 2D array of X and Y values\n",
    "array = rearranged_array\n",
    "    \n",
    "# Print the start format\n",
    "#print(print_start_format(ref_point, Z_var, array))   \n",
    "# Print the main pattern\n",
    "#print(print_pattern(G, F, Z_start, Z_end, array))\n",
    "# Print the end format\n",
    "#print(print_end_format(ref_point, Z_var, array))\n",
    "\n",
    "# Collect all outputs\n",
    "combined_output = []\n",
    "combined_output.extend(print_start_format(ref_point, Z_var, array))\n",
    "combined_output.extend(print_pattern(G, F, Z_start, Z_end, array))\n",
    "combined_output.extend(print_end_format(ref_point, Z_var, array))\n",
    "# Print the combined output\n",
    "#for line in combined_output:\n",
    "   # print(line)\n",
    "print('G-code Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff800cb-7e6a-4bc8-b705-51eb365ca82a",
   "metadata": {},
   "source": [
    "##### **Exporting Gcode to toolChanger**\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "base_url = \"\"\n",
    "def main():\n",
    "    PASSWORD = \"your_password\"\n",
    "    subtractive_gcode_file_path = f\"{OutputFileName}subtractive.gcode\"  # Define the output file name\n",
    "    \n",
    "    # Connect with password\n",
    "    if connect_with_password(PASSWORD):\n",
    "        # Save combined output to a G-code file\n",
    "        save_combined_output_to_file(combined_output, subtractive_gcode_file_path)\n",
    "        # Send the G-code file\n",
    "        filename = send_gcode_file(subtractive_gcode_file_path)\n",
    "        if filename:\n",
    "            # Send M23 command to select the file\n",
    "            send_gcode_command(f\"M23 {filename}\")\n",
    "            # Send M24 command to start the print\n",
    "            send_gcode_command(\"M24\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba262dc-de98-456e-8c35-c639c016de01",
   "metadata": {},
   "source": [
    "## 6.2 User Story 2\n",
    "**Digital Twins for Selective laser melting (SLM) Process Control**\n",
    "\n",
    "Selective laser melting (SLM) is a widely utilized technique in additive manufacturing for creating metal components with intricate geometries and high precision. However, its practical adoption is limited by inconsistent process reproducibility and unreliable product quality. This highlights the urgent need for in-situ quality monitoring and real-time process control. A feature-level multi-sensor fusion method is introduced, combining acoustic emission signals with photodiode signals for in-situ quality monitoring in SLM's intelligence-driven production. An off-axis monitoring system with a microphone and photodiode captures process signatures during building. Based on 2D porosity and 3D density measurements, the collected acoustic and optical signals are categorized to indicate part quality. Considering laser scanning data, a method is developed to transform 1D signals into 2D images, which are then used to train a convolutional neural network to extract and merge features from both sensors. Compared to several baseline models, the proposed multi-sensor fusion method delivers superior performance in quality monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75efbf-cdba-4fd9-aa25-aead71a8c0da",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.2.1 Digital Modeling</font>\n",
    "\n",
    "In this study, a digital model for in-situ quality monitoring is constructed using machine learning techniques, specifically a feature-level multi-sensor fusion approach based on 2D CNN. Acoustic emission and photodiode signals serve as input data, while the quality of the 3D-printed product is the output. The proposed method follows a three-step process: data acquisition and preprocessing, signal-to-image mapping, and CNN-based feature fusion for quality assessment. The overview of the digital modeling is shown below\n",
    "\n",
    "<center>\n",
    "    <img src=\"Module 6 Content/proposed_model.png\" alt=\"Drawing\" style=\"width: 600px;\" title=\" Experimental setup and a schematic representation of the SLM system\"/>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6663e2-f9c2-49eb-ab7e-2e04d3f9047a",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.2.2 Data Transmission</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf98346-d991-4607-9c7d-201f74ce7e14",
   "metadata": {},
   "source": [
    "##### **Photodiode raw data preprocessing and Signal-to-image Mapping**\n",
    "\n",
    "This is a sample code for collecting raw data from photodiode and data transmission.\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to read the photodiode raw data and convert it to image-based data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5b86c-6806-4c74-9338-2918357499a8",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "directory_path = \"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/photodiode\"\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.mat'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        mat_data = loadmat(file_path)\n",
    "        \n",
    "        data_name = os.path.splitext(filename)[0]\n",
    "        print(data_name+' is loaded')\n",
    "        data_dict[data_name] = mat_data\n",
    "\n",
    "x = list(data_dict.keys())[0]\n",
    "y = list(data_dict[x].keys())[3]\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "plt.plot(data_dict[x][y])\n",
    "plt.title(\"Raw photodiode signal sample\")\n",
    "plt.show()\n",
    "\n",
    "for j in range(len(data_dict.keys())):\n",
    "    \n",
    "    filename = list(data_dict.keys())[j]\n",
    "\n",
    "    parts = filename.split('_')\n",
    "    phd_grade = int(parts[1]) \n",
    "    phd_num = int(parts[2])\n",
    "    \n",
    "    filtered_data = []\n",
    "    data_all = []\n",
    "    for m in range(1,18):\n",
    "        x = data_dict[filename]['cDAQ1Mod4ai'+str(m)]\n",
    "        y = x[x>2]\n",
    "        filtered_data.append(y)\n",
    "\n",
    "    # folder = save_folder + str(phd_grade)\n",
    "    n = 32  # Size of each image\n",
    "\n",
    "    for i in range(1, 18):  # based on each layer, 17 layers in total\n",
    "        data = filtered_data[i-1]\n",
    "        N = len(data)\n",
    "        W = n * n  # Window size\n",
    "        hd = 10 * 10000 // 520  # Sliding step size\n",
    "        hdcs = (N - W) // hd + 1  # Number of sliding steps\n",
    "\n",
    "        for k in range(1, hdcs + 1):\n",
    "            one_data = data[(k-1) * hd: (k-1) * hd + W]\n",
    "            # Normalize and scale the data to 0-255\n",
    "            one_data = np.round((one_data - np.min(one_data)) / (np.max(one_data) - np.min(one_data)) * 255).astype(np.uint8)\n",
    "            # Reshape the image\n",
    "            one_data = one_data.reshape((n, n)) \n",
    "            \n",
    "            data_all.append(one_data)\n",
    "            # # Save the image\n",
    "            # image_filename = f'p_{phd_num}_{i}_{k}.png'\n",
    "            # image_path = os.path.join(folder, image_filename)\n",
    "            # Image.fromarray(one_data).save(image_path)\n",
    "\n",
    "    print(filename, \"Processing complete.\")\n",
    "\n",
    "data_sample = np.array(data_all[0])\n",
    "\n",
    "plt.imshow(data_sample)\n",
    "plt.title('Image sample from photodiode after data transmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23edd41-19e5-484a-8a0c-88f1c3fdf36b",
   "metadata": {},
   "source": [
    "##### **Microphone raw data preprocessing and Signal-to-image Mapping**\n",
    "\n",
    "This is a sample code for collecting microphone raw data and data transmission.\n",
    "\n",
    "##### **Press ‚ñ∂Ô∏è to read the microphone raw data and convert it to image-based data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067e76a-ed11-49b4-9a81-ce6ccfcb59b7",
   "metadata": {
    "has_explanation": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "data_dict = {}\n",
    "directory_path = \"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/microphone\"\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.mat'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        mat_data = loadmat(file_path)\n",
    "        \n",
    "        data_name = os.path.splitext(filename)[0]\n",
    "        print(data_name+' is loaded')\n",
    "        data_dict[data_name] = mat_data\n",
    "\n",
    "x = list(data_dict.keys())[0]\n",
    "y = list(data_dict[x].keys())[3]\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "plt.plot(data_dict[x][y])\n",
    "plt.title(\"Raw microphone signal sample\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(len(data_dict.keys())):\n",
    "    filename = list(data_dict.keys())[i]\n",
    "    parts = filename.split('_')\n",
    "    mcp_grade = int(parts[1]) \n",
    "    mcp_num = int(parts[2])\n",
    "    \n",
    "    filtered_data = []\n",
    "    data_all = []\n",
    "    for j in range(1,18):\n",
    "        x = data_dict[filename]['cDAQ1Mod2ai'+str(j)]\n",
    "#         print(x.shape)\n",
    "\n",
    "        data = x\n",
    "\n",
    "        data_1 = data.reshape(len(data),)\n",
    "        N = len(data)\n",
    "        fs = 10000  # Sampling frequency\n",
    "        t = np.arange(1, N+1)  # Sampling moments\n",
    "\n",
    "        # FFT of the data\n",
    "        data_fft = np.fft.fft(data_1)\n",
    "        df = fs / N  # Frequency sampling interval\n",
    "        data_f = np.arange(0, N) * df\n",
    "\n",
    "        # Find the indices where frequency is less than 4000 Hz\n",
    "        id0 = np.where(data_f < 4000)[0]\n",
    "        id0_len = len(id0)\n",
    "\n",
    "        # Filtering to make the low frequency part as 0\n",
    "        data_fft[id0] = 0\n",
    "        data_fft[-id0_len+1:] = 0\n",
    "\n",
    "        # Inverse FFT after filtering\n",
    "        data_ifft = np.real(np.fft.ifft(data_fft))\n",
    "        \n",
    "        data_ifft = data_ifft[1000:-1000]\n",
    "        \n",
    "        indices = np.where(data_ifft > 0.1)[0]\n",
    "        first_index = indices[0]\n",
    "        last_index = indices[-1]\n",
    "        \n",
    "        first_third_index = int((last_index - first_index)/3) + first_index\n",
    "        second_third_index = int(2*(last_index - first_index)/3) + first_index\n",
    "\n",
    "        first_valid_indices = indices[indices < first_third_index]\n",
    "        first_valid_indice = first_valid_indices[-1]\n",
    "        \n",
    "        second_valid_indices_start = indices[indices > first_third_index]\n",
    "        second_valid_indice_start = second_valid_indices_start[0]\n",
    "        second_valid_indices_end = indices[indices < second_third_index]\n",
    "        second_valid_indice_end = second_valid_indices_end[-1]\n",
    "        \n",
    "        third_valid_indices = indices[indices > second_third_index]\n",
    "        third_valid_indice = third_valid_indices[0]\n",
    "\n",
    "        if (j == 1) and (i==0):\n",
    "            # Plot the result\n",
    "            plt.plot(data_ifft)\n",
    "            plt.title(\"The acoustic signal after FFT filtering for \"+filename)\n",
    "            plt.axhline(0.1,color = 'r',linestyle='--')\n",
    "            plt.axhline(-0.1,color = 'r',linestyle='--')\n",
    "            plt.axvline(first_index,color = 'r')\n",
    "            plt.axvline(first_valid_indice,color = 'r')\n",
    "            plt.axvline(second_valid_indice_start,color = 'g')\n",
    "            plt.axvline(second_valid_indice_end,color = 'g')\n",
    "            plt.axvline(third_valid_indice,color = 'y')\n",
    "            plt.axvline(last_index,color = 'y')\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        y = np.concatenate([data_ifft[first_index:first_valid_indice],\n",
    "                            data_ifft[second_valid_indice_start:second_valid_indice_end],\n",
    "                            data_ifft[third_valid_indice:last_index]])\n",
    "#         print(y.shape)\n",
    "        filtered_data.append(y)\n",
    "       \n",
    "    # folder = save_folder + str(mcp_grade)\n",
    "    n = 32  # Size of each image\n",
    "\n",
    "    for m in range(1, 18):  # based on each layer, 17 layers in total\n",
    "        data = filtered_data[m-1]\n",
    "        N = len(data)\n",
    "        W = n * n  # Window size\n",
    "        hd = 10 * 10000 // 520  # Sliding step size\n",
    "        hdcs = (N - W) // hd + 1  # Number of sliding steps\n",
    "\n",
    "        for k in range(1, hdcs + 1):\n",
    "            one_data = data[(k-1) * hd: (k-1) * hd + W]\n",
    "            # Normalize and scale the data to 0-255\n",
    "            one_data = np.round((one_data - np.min(one_data)) / (np.max(one_data) - np.min(one_data)) * 255).astype(np.uint8)\n",
    "            # Reshape the image\n",
    "            one_data = one_data.reshape((n, n)) \n",
    "            \n",
    "            data_all.append(one_data)\n",
    "            # # Save the image\n",
    "            # image_filename = f'p_{mcp_num}_{m}_{k}.png'\n",
    "            # image_path = os.path.join(folder, image_filename)\n",
    "            # Image.fromarray(one_data).save(image_path)\n",
    "            \n",
    "    print(filename, \"Processing complete.\")\n",
    "\n",
    "data_sample = np.array(data_all[0])\n",
    "\n",
    "plt.imshow(data_sample)\n",
    "plt.title('Image sample from microphone after data transmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cf1d6-9dd1-42c5-99d1-a2061b23e53c",
   "metadata": {},
   "source": [
    "### <font color = '#646464'>6.2.3 Physical to Virtual</font>\n",
    "\n",
    "For selective laser melting (SLM), the **physical** domain consists of the manufacturing process itself, where metal powder is selectively melted layer by layer to create a final component. However, due to process variability, ensuring consistent quality remains a significant challenge.\n",
    "\n",
    "The **virtual** domain represents the digital modeling and monitoring of the SLM process, where sensor data is collected, processed, and analyzed to predict and control manufacturing quality. By bridging the physical and virtual worlds, we can achieve real-time insights and adaptive process control.\n",
    "\n",
    "To accomplish this transformation, an off-axis monitoring system captures physical process signatures using a microphone and a photodiode. These 1D acoustic and optical signals are then virtually processed by converting them into 2D image representations, incorporating laser scanning data. A convolutional neural network (CNN) extracts and fuses features from both sensors, enabling accurate in-situ quality assessment. This data-driven approach enhances process understanding and improves the reliability of SLM production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1fa00-9fbe-4de8-98bf-695252064f94",
   "metadata": {
    "has_explanation": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from ipywidgets import interact, IntSlider\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "all_path_microphone = []\n",
    "signal_microphone = os.listdir(\"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/image_data/microphone\")\n",
    "signal_microphone = signal_microphone[1:]\n",
    "for f, fsignal in enumerate(signal_microphone):\n",
    "    filepath = \"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/image_data/microphone\" + \"/\" + fsignal\n",
    "    filename = os.listdir(filepath)\n",
    "    for fname in filename:\n",
    "        ffpath = filepath + \"/\" + fname\n",
    "        path = [f, ffpath]\n",
    "        all_path_microphone.append(path)\n",
    "# print(len(all_path_microphone))\n",
    "\n",
    "def display_image_mcp(index):\n",
    "    img_path = all_path_microphone[index][1]\n",
    "    img = cv2.imread(img_path, 0)  \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "interact(display_image_mcp, index=IntSlider(min=0, max=len(all_path_microphone)-1, step=1, value=0,description='Microphone'))\n",
    "\n",
    "\n",
    "\n",
    "all_path_photodiode = []\n",
    "signal_photodiode = os.listdir(\"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/image_data/photodiode\")\n",
    "signal_photodiode = [x for x in signal_photodiode if x != '.DS_Store']\n",
    "\n",
    "for f, fsignal in enumerate(signal_photodiode):\n",
    "    filepath = os.path.join(\"../Examples/3. Advanced Topics/3.3. Sensor Fusion Processing/data/image_data/photodiode\", fsignal)\n",
    "    filename = os.listdir(filepath)\n",
    "    # Additional check for .DS_Store inside subdirectories\n",
    "    filename = [file for file in filename if file != '.DS_Store']\n",
    "    for fname in filename:\n",
    "        ffpath = os.path.join(filepath, fname)\n",
    "        path = [f, ffpath]\n",
    "        all_path_photodiode.append(path)\n",
    "\n",
    "# all_path_photodiode = []\n",
    "# signal_photodiode = os.listdir(\"../image_data/Photodiode\")\n",
    "# signal_photodiode = signal_photodiode[1:]\n",
    "# for f, fsignal in enumerate(signal_photodiode):\n",
    "#     filepath = \"../image_data/Photodiode\" + \"/\" + fsignal\n",
    "#     filename = os.listdir(filepath)\n",
    "#     for fname in filename:\n",
    "#         ffpath = filepath + \"/\" + fname\n",
    "#         path = [f, ffpath]\n",
    "#         all_path_photodiode.append(path)\n",
    "# # print(len(all_path_photodiode))\n",
    "\n",
    "def display_image_phd(index):\n",
    "    img_path = all_path_photodiode[index][1]\n",
    "    img = cv2.imread(img_path, 0)  \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "    \n",
    "interact(display_image_phd, index=IntSlider(min=0, max=len(all_path_photodiode)-1, step=1, value=0,description='Photodiode'))\n",
    "\n",
    "\n",
    "i=0\n",
    "data_x1_list = []\n",
    "data_x2_list = []\n",
    "data_y1_list = []\n",
    "data_y2_list = []\n",
    "\n",
    "for item1, item2 in zip(all_path_microphone,all_path_photodiode):\n",
    "    # print(item[0],item[1]) # 0 E:\\ml_datasets\\zhoucheng_data\\0\\0_1.png\n",
    "    if item1[0] == item2[0]:\n",
    "        img1=cv2.imread(item1[1],0)    \n",
    "        img2=cv2.imread(item2[1],0)  \n",
    "        \n",
    "        arr1 = np.asarray(img1, dtype=\"float32\")\n",
    "        data_x1_list.append(arr1)\n",
    "        \n",
    "        arr2 = np.asarray(img2, dtype=\"float32\")\n",
    "        data_x2_list.append(arr2)\n",
    "        \n",
    "        i += 1\n",
    "        data_y1_list.append(item1[0])\n",
    "        data_y2_list.append(item2[0])\n",
    "\n",
    "data_x1 = np.stack(data_x1_list, axis=0)[:, np.newaxis, :, :]\n",
    "data_y1 = np.stack(data_y1_list, axis=0)\n",
    "data_x2 = np.stack(data_x2_list, axis=0)[:, np.newaxis, :, :]\n",
    "data_y2 = np.stack(data_y2_list, axis=0)\n",
    "\n",
    "# print(data_x1.shape)\n",
    "# print(data_y1.shape)\n",
    "# print(data_x2.shape)\n",
    "# print(data_y2.shape)\n",
    "\n",
    "data_x1 = data_x1 / 255\n",
    "data_x2 = data_x2 / 255\n",
    "data_y1 = np.asarray(data_y1)\n",
    "data_y2 = np.asarray(data_y2)\n",
    "\n",
    "data_x1 = torch.from_numpy(data_x1)\n",
    "data_y1 = torch.from_numpy(data_y1)\n",
    "data_y1 = data_y1.long()\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(data_x1,\n",
    "                                                    data_y1,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=999,\n",
    "                                                    stratify=data_y1)\n",
    "data_x2 = torch.from_numpy(data_x2)\n",
    "data_y2 = torch.from_numpy(data_y2)\n",
    "data_y2 = data_y2.long()\n",
    "\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(data_x2,\n",
    "                                                    data_y2,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=999,\n",
    "                                                    stratify=data_y2)\n",
    "\n",
    "\n",
    "data1 = Data.TensorDataset(X1_train, X2_train, Y1_train)\n",
    "data2 = Data.TensorDataset(X1_test, X2_test, Y1_test)\n",
    "train_loader = Data.DataLoader(data1, batch_size=24,shuffle=True)\n",
    "valid_loader = Data.DataLoader(data2, batch_size=24)\n",
    "# print(len(data1))\n",
    "# print(len(data2))\n",
    "\n",
    "print('The sensor data is loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d06420-72fe-4c4d-b3fc-4b6e860d5155",
   "metadata": {},
   "source": [
    "##### **Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e7442-c6b3-479c-9215-970ca9ca015c",
   "metadata": {
    "has_explanation": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms,models\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.onnx\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CNN_original(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_original, self).__init__()  \n",
    "        self.conv1 = nn.Sequential(\n",
    "            # [1,64,64]\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,    \n",
    "                out_channels=16,  \n",
    "                kernel_size=5,    \n",
    "                stride=1,         \n",
    "                padding=2,        \n",
    "            ),\n",
    "            # [16,64,64] \n",
    "            nn.MaxPool2d(kernel_size=2)   # [16,32,32] \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,   \n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            # [32, 32, 32] \n",
    "            nn.MaxPool2d(kernel_size=2)  # [32,16,16] \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,    \n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            # [64, 16, 16]\n",
    "            nn.MaxPool2d(kernel_size=2)  # [64,8,8]\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,    \n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            # [64, 8, 8] \n",
    "            nn.MaxPool2d(kernel_size=2)  # [64,4,4] \n",
    "        )\n",
    "            \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(in_features=64*2*2*2, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=128, out_features=3)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x1, x2):           # [64√ó64√ó1]\n",
    "        x1 = self.conv1(x1)           # [64√ó64√ó16]\n",
    "        x1 = self.conv2(x1)           # [64√ó64√ó16]\n",
    "        \n",
    "        x2 = self.conv1(x2)           # [64√ó64√ó16]\n",
    "        x2 = self.conv2(x2)           # [64√ó64√ó16] \n",
    "           \n",
    "        \n",
    "        x = torch.cat((x1,x2),3)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)   \n",
    "               \n",
    "        output = self.output(x)     \n",
    "        return output\n",
    "\n",
    "model = CNN_original()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, conv_params):\n",
    "        super(CNN, self).__init__()\n",
    "        # Unpacking parameters for each layer\n",
    "        c1_out, c1_kernel, c1_stride, c1_padding = conv_params['conv1']\n",
    "        c2_out, c2_kernel, c2_stride, c2_padding = conv_params['conv2']\n",
    "        c3_out, c3_kernel, c3_stride, c3_padding = conv_params['conv3']\n",
    "        c4_out, c4_kernel, c4_stride, c4_padding = conv_params['conv4']\n",
    "\n",
    "        # Define the layers using the unpacked parameters\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, c1_out, c1_kernel, c1_stride, c1_padding),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(c1_out, c2_out, c2_kernel, c2_stride, c2_padding),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(c2_out, c3_out, c3_kernel, c3_stride, c3_padding),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(c3_out, c4_out, c4_kernel, c4_stride, c4_padding),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(c4_out * 4 * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.conv1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        \n",
    "        x2 = self.conv1(x2)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 3)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "# Function to create a slider with customized width\n",
    "def create_custom_slider(description, value, min, max, step):\n",
    "    return widgets.IntSlider(\n",
    "        value=value,\n",
    "        min=min,\n",
    "        max=max,\n",
    "        step=step,\n",
    "        description=description,\n",
    "        style={'description_width': 'initial'},  # This allows the description to take as much space as it needs\n",
    "        layout=widgets.Layout(width='50%')  # Adjust the width of the slider itself\n",
    "    )\n",
    "\n",
    "# Example usage in a model parameter context\n",
    "def create_param_sliders():\n",
    "    params = {\n",
    "        'conv1': [16, 5, 1, 2],  # example values: out_channels, kernel_size, stride, padding\n",
    "        'conv2': [32, 5, 1, 2],\n",
    "        'conv3': [64, 5, 1, 2],\n",
    "        'conv4': [64, 5, 1, 2]\n",
    "    }\n",
    "    sliders = {}\n",
    "    for layer, param in params.items():\n",
    "        sliders[layer] = [\n",
    "            create_custom_slider(f'{layer} out_channels', param[0], 16, 128, 16),\n",
    "            create_custom_slider(f'{layer} kernel_size', param[1], 3, 7, 1),\n",
    "            create_custom_slider(f'{layer} stride', param[2], 1, 3, 1),\n",
    "            create_custom_slider(f'{layer} padding', param[3], 0, 4, 1)\n",
    "        ]\n",
    "    return sliders\n",
    "\n",
    "sliders = create_param_sliders()\n",
    "ui = widgets.VBox([widgets.VBox(s) for s in sliders.values()])\n",
    "display(ui)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    conv_params = {k: [s.value for s in v] for k, v in sliders.items()}\n",
    "    global model_1\n",
    "    model_1 = CNN(conv_params)\n",
    "    print(model_1)\n",
    "    \n",
    "button = widgets.Button(description=\"Update Model\")\n",
    "button.on_click(on_button_clicked)\n",
    "display(button)\n",
    "\n",
    "def confusion_matrix(labels, preds, conf_matrix):\n",
    "    for p, t in zip(labels, preds):\n",
    "        conf_matrix[p, t] += 1\n",
    "    return conf_matrix\n",
    "\n",
    "\n",
    "\n",
    "summary(model, input_size=[(1, 32, 32), (1, 32, 32)])  # Specify the input size of the network\n",
    "# writer = SummaryWriter('runs/model_visualization')\n",
    "# dummy_input1 = torch.randn(1, 1, 32, 32)\n",
    "# dummy_input2 = torch.randn(1, 1, 32, 32)\n",
    "# writer.add_graph(model, (dummy_input1, dummy_input2))\n",
    "# writer.close()\n",
    "# torch.onnx.export(model, (dummy_input1, dummy_input2), \"model.onnx\")\n",
    "# !netron model.onnx\n",
    "\n",
    "\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "epochs = 30\n",
    "Train_epoch, Test_epoch, Train_accuracy, Test_accuracy, Loss = [], [], [], [], []\n",
    "Train_time, Test_time = [], []\n",
    "time0 = time.time()\n",
    "Predict_label, True_label = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    time1 = time.time()\n",
    "    Train_epoch.append(epoch + 1)\n",
    "    running_loss, running_correct = 0, 0\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    for data in tqdm(train_loader, desc=\"Training\"):\n",
    "        X1_train, X2_train, Y_train = data\n",
    "        # Assume model and data are on the same device, add .to(device) if needed\n",
    "        y_pred = model(X1_train, X2_train)\n",
    "        loss = loss_f(y_pred, Y_train)\n",
    "        pred = torch.max(y_pred, 1)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_correct += torch.sum(pred == Y_train).item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = running_correct / len(train_loader.dataset) *100\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train ACC: {train_acc:.4f}%\")\n",
    "\n",
    "    Train_time.append(time.time() - time1)\n",
    "    Loss.append(train_loss)\n",
    "    Train_accuracy.append(train_acc * 100)\n",
    "\n",
    "    # Validation loop with tqdm\n",
    "    test_loss, test_correct = 0, 0\n",
    "    conf_matrix = torch.zeros(3, 3)\n",
    "    for data in tqdm(valid_loader, desc=\"Validation\"):\n",
    "        X1_test, X2_test, Y_test = data\n",
    "        outputs = model(X1_test, X2_test)\n",
    "        pred = torch.max(outputs, 1)[1]\n",
    "        loss = loss_f(outputs, Y_test)\n",
    "        \n",
    "        if epoch == epochs-1:\n",
    "            Predict_label.append(pred.numpy())\n",
    "            True_label.append(Y_test.numpy())\n",
    "            conf_matrix = confusion_matrix(Y_test, pred, conf_matrix)\n",
    "            \n",
    "        test_loss += loss.item()\n",
    "        test_correct += torch.sum(pred == Y_test).item()\n",
    "\n",
    "    test_loss /= len(valid_loader.dataset)\n",
    "    test_accuracy = test_correct / len(valid_loader.dataset) *100\n",
    "    print(f\"Valid Loss: {test_loss:.4f}, Valid ACC: {test_accuracy:.4f}%\")\n",
    "\n",
    "    Test_accuracy.append(test_accuracy)\n",
    "    Test_time.append(time.time() - time1)\n",
    "\n",
    "# # Save results to files and print the confusion matrix\n",
    "# np.savetxt('CNN1-train_time_two_sensor_feature_micpho1_32.txt', Train_time, fmt=\"%.4f\")\n",
    "# np.savetxt('CNN1-test_time_two_sensor_feature_micpho1_32.txt', Test_time, fmt=\"%.4f\")\n",
    "# save_fn = 'CNN1_two_sensor_feature_micpho1_32.mat'\n",
    "# sio.savemat(save_fn, {'train_epoch': Train_epoch, 'train_accuracy': Train_accuracy,\n",
    "#                               'test_epoch': Test_epoch, 'test_accuracy': Test_accuracy,\n",
    "#                               'train_loss': Loss, \n",
    "#                               'predict_label': Predict_label, \n",
    "#                               'true_label': True_label})\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "import seaborn as sn\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "conf_matrix=conf_matrix.numpy()\n",
    "conf_matrix=conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "conf_matrix = np.around(conf_matrix, decimals=4)\n",
    "\n",
    "plt.rc('font',family='Times New Roman',size=16)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "df_cm = pd.DataFrame(conf_matrix,\n",
    "                     index = [\"Low quality\",\"Medium quality\",\"High quality\"],\n",
    "                     columns = [\"Low quality\",\"Medium quality\",\"High quality\"])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 24},cmap=\"Blues\",fmt='.4f')\n",
    "plt.gca().set_title('Confusion matrix',fontsize=24)\n",
    "plt.gca().set_xlabel('Predict label',fontsize=24)\n",
    "plt.gca().set_ylabel('True label',fontsize=24)\n",
    "#plt.gca().xaxis.set_ticks_position('none') \n",
    "#plt.gca().yaxis.set_ticks_position('none')\n",
    "plt.gca().set_yticklabels(plt.gca().get_yticklabels(), rotation=0)\n",
    "plt.grid(True, which='minor', linewidth=0.8 , linestyle='-')\n",
    "plt.subplots_adjust(top = 0.99, bottom = 0.12, right = 1.02, left = 0.12, hspace = 0, wspace = 0) #Ë∞ÉÊï¥ÂõæÂÉèËæπÁºò\n",
    "plt.margins(0,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7df9d-916f-4b84-bc60-719f4984781b",
   "metadata": {},
   "source": [
    "##### **Sample output**\n",
    "\n",
    "<img src=\"Module 6 Content/confusion_matrix.png\" alt=\"Sample Image\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4032c-c81f-4b14-847e-e44589af3169",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <font color = '#646464'>6.2.4 Virtual to Physical</font>\n",
    "As we described in the Green belt level, the manufacturing process can adjust some manufacturing parameters to improve the quality of the manufactured part using control algorithms based on the damage diagnostics results of the digital model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c9e9c",
   "metadata": {
    "tags": [
     "Bottom Navigation"
    ]
   },
   "source": [
    "### <center>[‚óÄÔ∏é Module 5](Module5.ipynb)‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ[üè† Home](../../welcomePage.ipynb)‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ[Module 7 ‚ñ∂Ô∏é](Module7.ipynb)</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
